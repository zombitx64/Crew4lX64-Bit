[
  {
    "url": "https://originshq.com/blog/top-ai-llm-learning-resource-in-2025/#ib-toc-anchor-0",
    "html": "8f69726f12a30e83",
    "cleaned_html": "e1cfe3f8e035905b",
    "markdown": "47c04b3f4a18970f",
    "extracted_content": "",
    "success": 1,
    "media": "{\"images\": [{\"src\": \"https://originshq.com/wp-content/uploads/2024/03/Origins-AI-500x250-1.png\", \"alt\": \"\", \"desc\": \"Home Blog Services Devops Cloud Data App Development AI Services Tech Consulting Our Works Raga AI \\u2013 AI Platform Samsung \\u2013 IOT Amazon \\u2013 Cost Reduction Nucash \\u2013 Building Platform FrontPage \\u2013 Scalability Issues YesMadam \\u2013 Digital Transformation Contact Us\", \"score\": 5, \"type\": \"image\", \"group_id\": 0, \"format\": \"png\", \"width\": null}, {\"src\": \"https://originshq.com/wp-content/uploads/2024/03/Origins-AI-500x250-1-300x150.png\", \"alt\": \"\", \"desc\": \"Home Blog Services Devops Cloud Data App Development AI Services Tech Consulting Our Works Raga AI \\u2013 AI Platform Samsung \\u2013 IOT Amazon \\u2013 Cost Reduction Nucash \\u2013 Building Platform FrontPage \\u2013 Scalability Issues YesMadam \\u2013 Digital Transformation Contact Us\", \"score\": 5, \"type\": \"image\", \"group_id\": 0, \"format\": \"png\", \"width\": 300}, {\"src\": \"https://originshq.com/wp-content/uploads/2025/01/top_learning_resource_ai_llm_in_2025.jpg\", \"alt\": \"Top AI/LLM learning resource in 2025\", \"desc\": \"Table of Contents \\ud83d\\udcdd Notebooks Tools Fine-tuning Quantization Other LLM Fundamentals 1. Mathematics for Machine Learning 2. Python for Machine Learning 3. Neural Networks 4. Natural Language Processing (NLP) The LLM Scientist 1. The LLM Architecture 2. Pre-training Models 3. Post-training Datasets 4. Supervised Fine-Tuning 5. Preference Alignment 6. Evaluation 7. Quantization 8. New Trends The LLM Engineer 1. Running LLMs 2. Building a Vector Storage 3. Retrieval Augmented Generation 4. Advanced RAG 5. Inference Optimization 6. Deploying LLMs 7. Securing LLMs Seeking Experts for Implementing AI ? The Blog is organized into three main segments: LLM Fundamentals (optional) \\u2013 Covers essential topics such as mathematics, Python, and neural networks. The LLM Scientist \\u2013 Concentrates on creating the best-performing LLMs using state-of-the-art techniques. The LLM Engineer \\u2013 Focuses on building applications based on LLMs and deploying them. \\ud83d\\udcdd Notebooks Below is a collection of notebooks and articles dedicated to LLMs. Tools Notebook Name Description Notebook \\ud83e\\uddd0 LLM AutoEval Evaluate your LLMs automatically using RunPod. Notebook \\ud83e\\udd71 LazyMergekit Merge models effortlessly using MergeKit with a single click. Notebook \\ud83e\\udd8e LazyAxolotl Fine-tune models in the cloud with Axolotl in just one click. Notebook \\u26a1 AutoQuant Quantize LLMs into GGUF, GPTQ, EXL2, AWQ, and HQQ formats in one click. Notebook \\ud83c\\udf33 Model Family Tree Visualize the lineage of merged models. Notebook \\ud83d\\ude80 ZeroSpace Instantly create a Gradio chat interface using a free ZeroGPU. Notebook Fine-tuning Notebook Name Description Article Notebook Fine-tune Llama 3.1 with Unsloth Perform ultra-efficient supervised fine-tuning in Google Colab. Article Notebook Fine-tune Llama 3 with ORPO Achieve cheaper and faster fine-tuning in a single stage with ORPO. Article Notebook Fine-tune Mistral-7b with DPO Enhance the performance of supervised fine-tuned models using DPO. Article Notebook Fine-tune Mistral-7b with QLoRA Supervised fine-tuning of Mistral-7b in a free-tier Google Colab using TRL. Notebook Fine-tune CodeLlama using Axolotl A comprehensive guide to fine-tune with the state-of-the-art Axolotl tool. Article Notebook Fine-tune Llama 2 with QLoRA A step-by-step guide to supervised fine-tuning of Llama 2 in Google Colab. Article Notebook Quantization Notebook Name Description Article Notebook Introduction to Quantization An overview of optimizing large language models using 8-bit quantization. Article Notebook 4-bit Quantization using GPTQ Learn to quantize your open-source LLMs for consumer hardware using GPTQ. Article Notebook Quantization with GGUF and llama.cpp Quantize Llama 2 models with llama.cpp and upload their GGUF versions to the HF Hub. Article Notebook ExLlamaV2: The Fastest Library to Run LLMs Quantize and run EXL2 models, then upload them to the HF Hub. Article Notebook Other Notebook Name Description Article Notebook Merge LLMs with MergeKit Easily create your own models without needing a GPU. Article Notebook Create MoEs with MergeKit Combine multiple experts into a single frankenMoE. Article Notebook Uncensor any LLM with abliteration Fine-tuning strategies without retraining the model. Article Notebook Improve ChatGPT with Knowledge Graphs Augment ChatGPT\\u2019s responses using knowledge graphs. Article Notebook Decoding Strategies in Large Language Models A comprehensive guide covering text generation methods from beam search to nucleus sampling. Article Notebook LLM Fundamentals This section provides core knowledge about mathematics, Python, and neural networks. While you may not begin here if you already have the basics, feel free to refer back as needed. 1. Mathematics for Machine Learning Before diving deep into machine learning, it is essential to master the fundamental mathematical concepts that underpin these algorithms: Linear Algebra : Crucial for many algorithms, particularly in deep learning. Topics include vectors, matrices, determinants, eigenvalues and eigenvectors, vector spaces, and linear transformations. Calculus : Needed to optimize continuous functions. Learn about derivatives, integrals, limits, series, multivariable calculus, and gradient concepts. Probability and Statistics : Key for understanding model behavior and data prediction. Essential topics include probability theory, random variables, distributions, expectations, variance, covariance, correlation, hypothesis testing, confidence intervals, maximum likelihood estimation, and Bayesian inference. Resources: 3Blue1Brown \\u2013 The Essence of Linear Algebra StatQuest with Josh Starmer \\u2013 Statistics Fundamentals AP Statistics Intuition by Ms Aerin Immersive Linear Algebra Khan Academy \\u2013 Linear Algebra Khan Academy \\u2013 Calculus Khan Academy \\u2013 Probability and Statistics 2. Python for Machine Learning Python is a flexible and powerful language, especially suited for machine learning because of its clear syntax and extensive ecosystem. Python Basics : Understand basic syntax, data types, error handling, and object-oriented programming. Data Science Libraries : Gain experience with NumPy for numerical operations; Pandas for data manipulation; and Matplotlib/Seaborn for visualizations. Data Preprocessing : Learn techniques such as feature scaling, normalization, handling missing values, outlier detection, encoding categorical data, and data splitting. Machine Learning Libraries : Familiarize yourself with Scikit-learn, which offers numerous supervised and unsupervised algorithms. Understand implementations of linear regression, logistic regression, decision trees, random forests, k-nearest neighbors, K-means clustering, and dimensionality reduction methods like PCA and t-SNE. Resources: Real Python freeCodeCamp \\u2013 Learn Python Python Data Science Handbook freeCodeCamp \\u2013 Machine Learning for Everybody Udacity \\u2013 Intro to Machine Learning 3. Neural Networks Neural networks form the backbone of many modern deep learning models. It\\u2019s important to understand how they work and are built: Fundamentals : Know the basic structure including layers, weights, biases, and activation functions (sigmoid, tanh, ReLU, etc.). Training and Optimization : Get to know backpropagation, common loss functions (MSE, Cross-Entropy), and optimization algorithms (Gradient Descent, SGD, RMSprop, Adam). Overfitting : Understand what overfitting means and study regularization techniques such as dropout, L1/L2 regularization, early stopping, and data augmentation. Implementing a Multilayer Perceptron (MLP) : Build an MLP (a fully connected network) using frameworks like PyTorch. Resources: 3Blue1Brown \\u2013 But what is a Neural Network? freeCodeCamp \\u2013 Deep Learning Crash Course Fast.ai \\u2013 Practical Deep Learning Patrick Loeber \\u2013 PyTorch Tutorials 4. Natural Language Processing (NLP) NLP is an exciting field that connects human language with machine comprehension. It ranges from basic text processing to capturing intricate linguistic nuances. Text Preprocessing : Understand tokenization (dividing text into words or sentences), stemming (reducing words to their roots), lemmatization (context-aware reduction), and stop word removal. Feature Extraction Techniques : Learn how to transform textual data for machine learning algorithms using techniques like Bag-of-Words (BoW), TF-IDF, and n-grams. Word Embeddings : Study methods such as Word2Vec, GloVe, and FastText which allow words with similar meanings to have similar vector representations. Recurrent Neural Networks (RNNs) : Learn how RNNs are designed for sequential data and explore variants like LSTMs and GRUs, which capture long-term dependencies. Resources: Lena Voita \\u2013 Word Embeddings RealPython \\u2013 NLP with spaCy in Python Kaggle \\u2013 NLP Guide Jay Alammar \\u2013 The Illustration Word2Vec Jake Tae \\u2013 PyTorch RNN from Scratch colah\\u2019s blog \\u2013 Understanding LSTM Networks The LLM Scientist This section is designed to help you learn how to build the most effective LLMs using the latest methodologies. 1. The LLM Architecture You don\\u2019t need an exhaustive understanding of the Transformer architecture, but it is important to know the major steps in modern LLMs: converting text into numeric tokens, processing these tokens with layers (including attention mechanisms), and using various sampling strategies to generate text. Architectural Overview : Trace the evolution from encoder-decoder Transformers to decoder-only structures like GPT, which are fundamental to modern LLMs. Understand how these models process and generate text at a high level. Tokenization : Learn the principles behind tokenization and how it transforms text into numerical data that models can process. Investigate different tokenization strategies and their effects on performance and output quality. Attention Mechanisms : Master the concept of attention, particularly self-attention and its variants, and see how they help models deal with long-range dependencies and maintain contextual integrity. Sampling Techniques : Compare deterministic methods (e.g., greedy search, beam search) to probabilistic methods (e.g., temperature sampling, nucleus sampling) and evaluate the trade-offs involved. References: Visual intro to Transformers by 3Blue1Brown LLM Visualization by Brendan Bycroft nanoGPT by Andrej Karpathy (includes a tokenization video: here ) Attention? Attention! by Lilian Weng Decoding Strategies in LLMs by Maxime Labonne 2. Pre-training Models Pre-training LLMs is an expensive and resource-intensive process. Although this course does not primarily focus on pre-training, understanding the process, particularly regarding data handling and model parameters, is crucial. For smaller-scale hobbyist projects, pre-training on models with fewer than 1B parameters is feasible. Data Preparation : Pre-training requires vast datasets (for example, Llama 3.1 was trained on 15 trillion tokens), which must be curated, cleaned, deduplicated, and tokenized. Modern pipelines include extensive quality filtering. Distributed Training : Explore techniques such as data parallelism (distributing batches), pipeline parallelism (distributing layers), and tensor parallelism (splitting operations). These require effective network communication and memory management across GPU clusters. Training Optimization : Utilize adaptive learning rate schedules with warm-up, gradient clipping and normalization, mixed-precision training, and modern optimizers (AdamW, Lion) with well-tuned hyperparameters. Monitoring : Implement dashboards and logging to track metrics (loss, gradients, GPU usage) and profile performance to identify computational and communication bottlenecks. References: FineWeb by Penedo et al. RedPajama v2 by Weber et al. nanotron by Hugging Face (used for SmolLM2 ) Parallel Training by Chenyan Xiong Distributed Training by Duan et al. OLMo 2 by AI2 LLM360 by LLM360 3. Post-training Datasets Post-training datasets are organized with clear structures including instructions paired with answers (supervised fine-tuning) or instructions paired with chosen/rejected responses (preference alignment). Given that conversational datasets are less common compared to raw pre-training data, additional processing is often needed to enhance sample accuracy, diversity, and complexity. More details can be found in the \\ud83d\\udcbe LLM Datasets repository. Storage & Chat Templates : Due to their conversational nature, these datasets are stored in formats such as ShareGPT or OpenAI/HF. These are then mapped to chat templates like ChatML or Alpaca for training. Synthetic Data Generation : Use frontier models like GPT-4o to create instruction-response pairs from seed data. This method offers flexibility and scalability, with considerations for diverse seed tasks and effective system prompts. Data Enhancement : Enhance your samples with techniques including verified outputs (using unit tests/solvers), generating multiple answers with rejection sampling, Auto-Evol , Chain-of-Thought, Branch-Solve-Merge, persona-based approaches, and more. Quality Filtering : Traditional filtering methods involve rule-based approaches, duplicate removal (using MinHash or embeddings), and n-gram decontamination, with reward models and judge LLMs providing additional quality control. References: Synthetic Data Generator by Argilla LLM Datasets by Maxime Labonne NeMo-Curator by Nvidia Distilabel by Argilla Semhash by MinishLab Chat Template by Hugging Face 4. Supervised Fine-Tuning Supervised Fine-Tuning (SFT) transforms base models into helpful assistants capable of following instructions and structuring answers effectively. Although SFT can be used to introduce new knowledge, its ability to completely learn a new language is limited. Thus, prioritizing data quality over parameter tuning is essential. Training Techniques : Full fine-tuning updates all parameters but requires significant computational resources. Techniques like LoRA and QLoRA update only a small number of adapter parameters while keeping the base model frozen. QLoRA further combines 4-bit quantization with LoRA to minimize VRAM usage. Training Parameters : Important parameters to manage include the learning rate (with schedulers), batch size, gradient accumulation, number of epochs, optimizers (e.g., 8-bit AdamW), weight decay, warmup steps, and specific LoRA parameters (rank, alpha, target modules). Distributed Training : Utilize multiple GPUs via frameworks such as DeepSpeed or FSDP. DeepSpeed offers ZeRO optimization stages to improve memory efficiency by partitioning state information. Both frameworks support gradient checkpointing. Monitoring : Keep an eye on metrics like loss curves, learning rate changes, and gradient norms, while addressing issues such as loss spikes or gradient explosions. References: Fine-tune Llama 3.1 Ultra-Efficiently with Unsloth by Maxime Labonne Axolotl \\u2013 Documentation by Wing Lian Mastering LLMs by Hamel Husain LoRA insights by Sebastian Raschka 5. Preference Alignment Preference alignment is a secondary stage in the post-training process that helps fine-tune the model\\u2019s tone and reduce issues like toxicity and hallucinations. Its purpose is to improve performance and usefulness, and it generally involves methods like Direct Preference Optimization (DPO) and Proximal Policy Optimization (PPO). Rejection Sampling : For each prompt, generate multiple responses from the model, then score them to create on-policy data consisting of both chosen and rejected answers. Direct Preference Optimization : This method optimizes the policy by directly increasing the likelihood of chosen responses over rejected ones, without needing a separate reward model. Although it is more computationally efficient than PPO, it may offer a slight decrease in quality. Proximal Policy Optimization : This method iteratively updates the policy to maximize rewards while keeping changes close to the original behavior, using a reward model to score responses and requiring careful hyperparameter tuning (learning rate, batch size, and PPO clip range). Monitoring : Alongside SFT metrics, monitor the margin between chosen and rejected responses and track overall accuracy improvements until reaching a plateau. References: Illustrating RLHF by Hugging Face LLM Training: RLHF and Its Alternatives by Sebastian Raschka Preference Tuning LLMs by Hugging Face Fine-tune Mistral-7b with DPO by Maxime Labonne DPO Wandb logs by Alexander Vishnevskiy 6. Evaluation Evaluating LLMs reliably is a challenging but essential task for refining dataset composition and training settings. It is important to acknowledge Goodhart\\u2019s law: \\u201cWhen a measure becomes a target, it ceases to be a good measure.\\u201d Automated Benchmarks : Use curated datasets and metrics (such as MMLU) to assess performance on specific tasks. This approach works well for concrete tasks but may struggle with abstract capabilities and suffer from data contamination. Human Evaluation : Involve human assessors to prompt models and rate outputs. This method ranges from informal checks to systematic annotations and large-scale community voting (arena) and tends to work best for subjective assessments. Model-based Evaluation : Implement judge or reward models to assess generated responses. Although they often correlate well with human judgment, these models may be biased toward their own outputs. Feedback Signal : Analyze error patterns to identify shortcomings, such as problems following complex instructions, lacking specific knowledge, or being vulnerable to adversarial prompts. Use the feedback to adjust data generation and training parameters. References: Evaluation Guidebook by Cl\\u00e9mentine Fourrier Open LLM Leaderboard by Hugging Face Language Model Evaluation Harness by EleutherAI Lighteval by Hugging Face Chatbot Arena by LMSYS 7. Quantization Quantization converts a model\\u2019s parameters and activations from high precision (e.g., FP32) to lower precision (such as 4 bits) to reduce compute and memory requirements. Base Techniques : Understand the different precisions (FP32, FP16, INT8, etc.) and basic quantization methods like absmax and zero-point techniques. GGUF & llama.cpp : Originally created for CPU-based runs, llama.cpp and the GGUF format are now widely used to run LLMs on consumer hardware. They support the storage of special tokens, vocabulary, and metadata all in one file. GPTQ & AWQ : Methods such as GPTQ / EXL2 and AWQ use layer-wise calibration to maintain performance at very low bitwidths. These techniques adjust scaling dynamically and can selectively bypass or re-center the heaviest parameters. SmoothQuant & ZeroQuant : New methods such as SmoothQuant (which applies quantization-friendly transformations) and compiler-based optimizations like ZeroQuant help alleviate outlier issues before quantization, optimizing data flow and reducing hardware overhead. References: Introduction to Quantization by Maxime Labonne Quantize Llama models with llama.cpp by Maxime Labonne 4-bit LLM Quantization with GPTQ by Maxime Labonne Understanding Activation-Aware Weight Quantization by FriendliAI SmoothQuant on Llama 2 7B by MIT HAN Lab DeepSpeed Model Compression by DeepSpeed 8. New Trends This section covers emerging topics that do not neatly fit into other categories. Some ideas, like model merging and multimodal models, are well established, while others\\u2014such as interpretability or test-time compute scaling\\u2014are more experimental and actively researched. Model Merging : Merging pre-trained models has become a popular technique for boosting performance without additional fine-tuning. The mergekit library implements several popular merging methods, including SLERP, DARE , and TIES . Multimodal Models : Models like CLIP , Stable Diffusion , and LLaVA are designed to process and integrate various types of inputs (text, images, audio, etc.) within a unified embedding space, enabling powerful applications such as text-to-image generation. Interpretability : Mechanistic interpretability approaches, including Sparse Autoencoders (SAEs) and techniques like abliteration, offer insights into the internal operations of LLMs and can allow for behavioral adjustments without retraining. Test-time Compute : Scaling computational resources during inference often requires multiple calls and specialized models (e.g., Process Reward Model (PRM)). Iterative procedures with fine-tuned scoring can markedly enhance performance on complex reasoning tasks. References: Merge LLMs with mergekit by Maxime Labonne Smol Vision by Merve Noyan Large Multimodal Models by Chip Huyen Uncensor any LLM with abliteration by Maxime Labonne Intuitive Explanation of SAEs by Adam Karvonen Scaling test-time compute by Beeching et al. The LLM Engineer This part of the course teaches you how to build production-grade applications powered by LLMs, with a focus on augmenting models and deploying them. 1. Running LLMs Running LLMs can be challenging given their high hardware requirements. Depending on your needs, you might opt to use an API (like GPT-4) or run a model locally. In either case, careful prompting and guidance can greatly enhance output quality and relevance. LLM APIs : APIs provide a convenient way to access LLMs. They are divided between private LLMs (e.g., OpenAI , Google , Anthropic , Cohere ) and open-source LLMs (e.g., OpenRouter , Hugging Face , Together AI ). Open-source LLMs : The Hugging Face Hub is a prime resource for finding LLMs. You can run many of these models in Hugging Face Spaces , or download and operate them locally using tools like LM Studio , llama.cpp , or Ollama . Prompt Engineering : Techniques such as zero-shot prompting, few-shot prompting, chain-of-thought, and ReAct are common. While these methods work better with larger models, they can be adapted for smaller ones. Structuring Outputs : Some tasks require outputs to follow a strict format (such as a JSON format or specific template). Tools such as LMQL , Outlines , and Guidance help ensure the generated text adheres to the required structure. References: Run an LLM locally with LM Studio by Nisha Arya Prompt engineering guide by DAIR.AI Outlines \\u2013 Quickstart LMQL \\u2013 Overview 2. Building a Vector Storage The first step in creating a Retrieval Augmented Generation (RAG) pipeline is establishing a vector storage. This involves loading documents, splitting them into manageable pieces, and then converting key text chunks into vector embeddings for future retrieval. Ingesting Documents : Document loaders can process multiple formats such as PDF, JSON, HTML, and Markdown. They can also pull in data directly from databases and APIs (e.g., GitHub, Reddit, Google Drive). Splitting Documents : Text splitters divide documents into smaller, semantically relevant chunks. Instead of a fixed character count, splitting by headers or recursively\\u2014while preserving metadata\\u2014often yields better results. Embedding Models : These models transform text into vector representations, enabling a more nuanced semantic interpretation that is essential for effective search. Vector Databases : Databases like Chroma , Pinecone , Milvus , FAISS , and Annoy are designed for storing embeddings, allowing for fast similarity-based retrieval. References: LangChain \\u2013 Text splitters Sentence Transformers library MTEB Leaderboard The Top 5 Vector Databases by Moez Ali 3. Retrieval Augmented Generation Retrieval Augmented Generation (RAG) enhances LLM outputs by using relevant contextual documents fetched from a vector database, thus improving answer accuracy without needing additional fine-tuning. Orchestrators : Tools like LangChain , LlamaIndex , and FastRAG connect LLMs to tools, databases, and memory systems, extending their functionality. Retrievers : Since user queries may not be optimized for search, techniques such as multi-query retrievers or HyDE can reformulate queries to improve retrieval performance. Memory : To maintain context over a conversation, LLMs use a history buffer that can be enhanced with summarization techniques or integrated with vector stores via RAG. Evaluation : It is crucial to assess both the document retrieval process (precision and recall) and the generation stage (faithfulness and relevancy). Tools like Ragas and DeepEval can assist in these evaluations. References: Llamaindex \\u2013 High-level concepts Pinecone \\u2013 Retrieval Augmentation LangChain \\u2013 Q&A with RAG LangChain \\u2013 Memory types RAG pipeline \\u2013 Metrics 4. Advanced RAG In real-world scenarios, you may need to develop more complex pipelines involving SQL or graph databases, as well as systems that automatically select appropriate tools and APIs to enhance the baseline RAG setup. Query Construction : For structured data stored in databases, you need to translate user instructions into appropriate query languages like SQL or Cypher. Agents and Tools : LLM agents can automatically choose the most suitable tools\\u2014ranging from simple web searches (e.g., Google, Wikipedia) to complex systems (e.g., Python interpreters, Jira)\\u2014to answer queries. Post-Processing : Enhance the overall relevance of retrieved documents using re-ranking methods, RAG-fusion , or classification techniques. Program LLMs : Frameworks like DSPy allow you to fine-tune prompts and model parameters programmatically based on automated evaluations. References: LangChain \\u2013 Query Construction LangChain \\u2013 SQL Pinecone \\u2013 LLM agents LLM Powered Autonomous Agents by Lilian Weng LangChain \\u2013 OpenAI\\u2019s RAG DSPy in 8 Steps 5. Inference Optimization Since generating text is computationally intensive, several techniques exist to maximize throughput and reduce inference costs alongside quantization. Flash Attention : Optimizes the attention mechanism by reducing its complexity from quadratic to linear, thereby speeding up both training and inference. Key-value Cache : Learn about the key-value cache and enhancements like Multi-Query Attention (MQA) and Grouped-Query Attention (GQA). Speculative Decoding : Use a smaller model to produce draft outputs that are later refined by a larger model, thus accelerating text generation. References: GPU Inference by Hugging Face LLM Inference by Databricks Optimizing LLMs for Speed and Memory by Hugging Face Assisted Generation by Hugging Face 6. Deploying LLMs Deploying LLMs, especially at scale, is complex and may require multiple GPU clusters. However, demos or local applications often have simpler requirements. Local Deployment : Open-source LLMs offer privacy advantages over private models. Solutions such as LM Studio , Ollama , oobabooga , and kobold.cpp facilitate local deployment. Demo Deployment : Tools like Gradio and Streamlit are excellent for prototyping apps and sharing demos. They are also easy to host online (for example, on Hugging Face Spaces ). Server Deployment : Running LLMs at scale often demands cloud infrastructure (or on-prem solutions) and specialized frameworks such as TGI or vLLM . Edge Deployment : In resource-constrained environments, frameworks like MLC LLM and mnn-llm enable deployment on web browsers, Android, and iOS. References: Streamlit \\u2013 Build a basic LLM app by Streamlit HF LLM Inference Container by Hugging Face Philschmid blog by Philipp Schmid Optimizing Latency by Hamel Husain 7. Securing LLMs LLM applications bring their own unique security challenges in addition to standard software vulnerabilities. Prompt Hacking : This includes issues like prompt injection (where unwanted instructions hijack the model), data/prompt leaking (extracting the original prompt or training data), and jailbreaking (bypassing the model\\u2019s safety features). Backdoors : These attacks can target training data by poisoning it with false or malicious content, or by introducing hidden triggers that alter model behavior during inference. Defensive Measures : Protect your LLM applications by testing them for vulnerabilities using techniques such as red teaming and tools like garak , while monitoring in production with frameworks like langfuse . References: OWASP LLM Top 10 by HEGO Wiki Prompt Injection Primer by Joseph Thacker LLM Security by @llm_sec Red teaming LLMs by Microsoft \\u2190 Previous Next \\u2192\", \"score\": 5, \"type\": \"image\", \"group_id\": 1, \"format\": \"jpg\", \"width\": null}, {\"src\": \"https://originshq.com/wp-content/uploads/2025/01/top_learning_resource_ai_llm_in_2025-300x169.jpg\", \"alt\": \"Top AI/LLM learning resource in 2025\", \"desc\": \"Table of Contents \\ud83d\\udcdd Notebooks Tools Fine-tuning Quantization Other LLM Fundamentals 1. Mathematics for Machine Learning 2. Python for Machine Learning 3. Neural Networks 4. Natural Language Processing (NLP) The LLM Scientist 1. The LLM Architecture 2. Pre-training Models 3. Post-training Datasets 4. Supervised Fine-Tuning 5. Preference Alignment 6. Evaluation 7. Quantization 8. New Trends The LLM Engineer 1. Running LLMs 2. Building a Vector Storage 3. Retrieval Augmented Generation 4. Advanced RAG 5. Inference Optimization 6. Deploying LLMs 7. Securing LLMs Seeking Experts for Implementing AI ? The Blog is organized into three main segments: LLM Fundamentals (optional) \\u2013 Covers essential topics such as mathematics, Python, and neural networks. The LLM Scientist \\u2013 Concentrates on creating the best-performing LLMs using state-of-the-art techniques. The LLM Engineer \\u2013 Focuses on building applications based on LLMs and deploying them. \\ud83d\\udcdd Notebooks Below is a collection of notebooks and articles dedicated to LLMs. Tools Notebook Name Description Notebook \\ud83e\\uddd0 LLM AutoEval Evaluate your LLMs automatically using RunPod. Notebook \\ud83e\\udd71 LazyMergekit Merge models effortlessly using MergeKit with a single click. Notebook \\ud83e\\udd8e LazyAxolotl Fine-tune models in the cloud with Axolotl in just one click. Notebook \\u26a1 AutoQuant Quantize LLMs into GGUF, GPTQ, EXL2, AWQ, and HQQ formats in one click. Notebook \\ud83c\\udf33 Model Family Tree Visualize the lineage of merged models. Notebook \\ud83d\\ude80 ZeroSpace Instantly create a Gradio chat interface using a free ZeroGPU. Notebook Fine-tuning Notebook Name Description Article Notebook Fine-tune Llama 3.1 with Unsloth Perform ultra-efficient supervised fine-tuning in Google Colab. Article Notebook Fine-tune Llama 3 with ORPO Achieve cheaper and faster fine-tuning in a single stage with ORPO. Article Notebook Fine-tune Mistral-7b with DPO Enhance the performance of supervised fine-tuned models using DPO. Article Notebook Fine-tune Mistral-7b with QLoRA Supervised fine-tuning of Mistral-7b in a free-tier Google Colab using TRL. Notebook Fine-tune CodeLlama using Axolotl A comprehensive guide to fine-tune with the state-of-the-art Axolotl tool. Article Notebook Fine-tune Llama 2 with QLoRA A step-by-step guide to supervised fine-tuning of Llama 2 in Google Colab. Article Notebook Quantization Notebook Name Description Article Notebook Introduction to Quantization An overview of optimizing large language models using 8-bit quantization. Article Notebook 4-bit Quantization using GPTQ Learn to quantize your open-source LLMs for consumer hardware using GPTQ. Article Notebook Quantization with GGUF and llama.cpp Quantize Llama 2 models with llama.cpp and upload their GGUF versions to the HF Hub. Article Notebook ExLlamaV2: The Fastest Library to Run LLMs Quantize and run EXL2 models, then upload them to the HF Hub. Article Notebook Other Notebook Name Description Article Notebook Merge LLMs with MergeKit Easily create your own models without needing a GPU. Article Notebook Create MoEs with MergeKit Combine multiple experts into a single frankenMoE. Article Notebook Uncensor any LLM with abliteration Fine-tuning strategies without retraining the model. Article Notebook Improve ChatGPT with Knowledge Graphs Augment ChatGPT\\u2019s responses using knowledge graphs. Article Notebook Decoding Strategies in Large Language Models A comprehensive guide covering text generation methods from beam search to nucleus sampling. Article Notebook LLM Fundamentals This section provides core knowledge about mathematics, Python, and neural networks. While you may not begin here if you already have the basics, feel free to refer back as needed. 1. Mathematics for Machine Learning Before diving deep into machine learning, it is essential to master the fundamental mathematical concepts that underpin these algorithms: Linear Algebra : Crucial for many algorithms, particularly in deep learning. Topics include vectors, matrices, determinants, eigenvalues and eigenvectors, vector spaces, and linear transformations. Calculus : Needed to optimize continuous functions. Learn about derivatives, integrals, limits, series, multivariable calculus, and gradient concepts. Probability and Statistics : Key for understanding model behavior and data prediction. Essential topics include probability theory, random variables, distributions, expectations, variance, covariance, correlation, hypothesis testing, confidence intervals, maximum likelihood estimation, and Bayesian inference. Resources: 3Blue1Brown \\u2013 The Essence of Linear Algebra StatQuest with Josh Starmer \\u2013 Statistics Fundamentals AP Statistics Intuition by Ms Aerin Immersive Linear Algebra Khan Academy \\u2013 Linear Algebra Khan Academy \\u2013 Calculus Khan Academy \\u2013 Probability and Statistics 2. Python for Machine Learning Python is a flexible and powerful language, especially suited for machine learning because of its clear syntax and extensive ecosystem. Python Basics : Understand basic syntax, data types, error handling, and object-oriented programming. Data Science Libraries : Gain experience with NumPy for numerical operations; Pandas for data manipulation; and Matplotlib/Seaborn for visualizations. Data Preprocessing : Learn techniques such as feature scaling, normalization, handling missing values, outlier detection, encoding categorical data, and data splitting. Machine Learning Libraries : Familiarize yourself with Scikit-learn, which offers numerous supervised and unsupervised algorithms. Understand implementations of linear regression, logistic regression, decision trees, random forests, k-nearest neighbors, K-means clustering, and dimensionality reduction methods like PCA and t-SNE. Resources: Real Python freeCodeCamp \\u2013 Learn Python Python Data Science Handbook freeCodeCamp \\u2013 Machine Learning for Everybody Udacity \\u2013 Intro to Machine Learning 3. Neural Networks Neural networks form the backbone of many modern deep learning models. It\\u2019s important to understand how they work and are built: Fundamentals : Know the basic structure including layers, weights, biases, and activation functions (sigmoid, tanh, ReLU, etc.). Training and Optimization : Get to know backpropagation, common loss functions (MSE, Cross-Entropy), and optimization algorithms (Gradient Descent, SGD, RMSprop, Adam). Overfitting : Understand what overfitting means and study regularization techniques such as dropout, L1/L2 regularization, early stopping, and data augmentation. Implementing a Multilayer Perceptron (MLP) : Build an MLP (a fully connected network) using frameworks like PyTorch. Resources: 3Blue1Brown \\u2013 But what is a Neural Network? freeCodeCamp \\u2013 Deep Learning Crash Course Fast.ai \\u2013 Practical Deep Learning Patrick Loeber \\u2013 PyTorch Tutorials 4. Natural Language Processing (NLP) NLP is an exciting field that connects human language with machine comprehension. It ranges from basic text processing to capturing intricate linguistic nuances. Text Preprocessing : Understand tokenization (dividing text into words or sentences), stemming (reducing words to their roots), lemmatization (context-aware reduction), and stop word removal. Feature Extraction Techniques : Learn how to transform textual data for machine learning algorithms using techniques like Bag-of-Words (BoW), TF-IDF, and n-grams. Word Embeddings : Study methods such as Word2Vec, GloVe, and FastText which allow words with similar meanings to have similar vector representations. Recurrent Neural Networks (RNNs) : Learn how RNNs are designed for sequential data and explore variants like LSTMs and GRUs, which capture long-term dependencies. Resources: Lena Voita \\u2013 Word Embeddings RealPython \\u2013 NLP with spaCy in Python Kaggle \\u2013 NLP Guide Jay Alammar \\u2013 The Illustration Word2Vec Jake Tae \\u2013 PyTorch RNN from Scratch colah\\u2019s blog \\u2013 Understanding LSTM Networks The LLM Scientist This section is designed to help you learn how to build the most effective LLMs using the latest methodologies. 1. The LLM Architecture You don\\u2019t need an exhaustive understanding of the Transformer architecture, but it is important to know the major steps in modern LLMs: converting text into numeric tokens, processing these tokens with layers (including attention mechanisms), and using various sampling strategies to generate text. Architectural Overview : Trace the evolution from encoder-decoder Transformers to decoder-only structures like GPT, which are fundamental to modern LLMs. Understand how these models process and generate text at a high level. Tokenization : Learn the principles behind tokenization and how it transforms text into numerical data that models can process. Investigate different tokenization strategies and their effects on performance and output quality. Attention Mechanisms : Master the concept of attention, particularly self-attention and its variants, and see how they help models deal with long-range dependencies and maintain contextual integrity. Sampling Techniques : Compare deterministic methods (e.g., greedy search, beam search) to probabilistic methods (e.g., temperature sampling, nucleus sampling) and evaluate the trade-offs involved. References: Visual intro to Transformers by 3Blue1Brown LLM Visualization by Brendan Bycroft nanoGPT by Andrej Karpathy (includes a tokenization video: here ) Attention? Attention! by Lilian Weng Decoding Strategies in LLMs by Maxime Labonne 2. Pre-training Models Pre-training LLMs is an expensive and resource-intensive process. Although this course does not primarily focus on pre-training, understanding the process, particularly regarding data handling and model parameters, is crucial. For smaller-scale hobbyist projects, pre-training on models with fewer than 1B parameters is feasible. Data Preparation : Pre-training requires vast datasets (for example, Llama 3.1 was trained on 15 trillion tokens), which must be curated, cleaned, deduplicated, and tokenized. Modern pipelines include extensive quality filtering. Distributed Training : Explore techniques such as data parallelism (distributing batches), pipeline parallelism (distributing layers), and tensor parallelism (splitting operations). These require effective network communication and memory management across GPU clusters. Training Optimization : Utilize adaptive learning rate schedules with warm-up, gradient clipping and normalization, mixed-precision training, and modern optimizers (AdamW, Lion) with well-tuned hyperparameters. Monitoring : Implement dashboards and logging to track metrics (loss, gradients, GPU usage) and profile performance to identify computational and communication bottlenecks. References: FineWeb by Penedo et al. RedPajama v2 by Weber et al. nanotron by Hugging Face (used for SmolLM2 ) Parallel Training by Chenyan Xiong Distributed Training by Duan et al. OLMo 2 by AI2 LLM360 by LLM360 3. Post-training Datasets Post-training datasets are organized with clear structures including instructions paired with answers (supervised fine-tuning) or instructions paired with chosen/rejected responses (preference alignment). Given that conversational datasets are less common compared to raw pre-training data, additional processing is often needed to enhance sample accuracy, diversity, and complexity. More details can be found in the \\ud83d\\udcbe LLM Datasets repository. Storage & Chat Templates : Due to their conversational nature, these datasets are stored in formats such as ShareGPT or OpenAI/HF. These are then mapped to chat templates like ChatML or Alpaca for training. Synthetic Data Generation : Use frontier models like GPT-4o to create instruction-response pairs from seed data. This method offers flexibility and scalability, with considerations for diverse seed tasks and effective system prompts. Data Enhancement : Enhance your samples with techniques including verified outputs (using unit tests/solvers), generating multiple answers with rejection sampling, Auto-Evol , Chain-of-Thought, Branch-Solve-Merge, persona-based approaches, and more. Quality Filtering : Traditional filtering methods involve rule-based approaches, duplicate removal (using MinHash or embeddings), and n-gram decontamination, with reward models and judge LLMs providing additional quality control. References: Synthetic Data Generator by Argilla LLM Datasets by Maxime Labonne NeMo-Curator by Nvidia Distilabel by Argilla Semhash by MinishLab Chat Template by Hugging Face 4. Supervised Fine-Tuning Supervised Fine-Tuning (SFT) transforms base models into helpful assistants capable of following instructions and structuring answers effectively. Although SFT can be used to introduce new knowledge, its ability to completely learn a new language is limited. Thus, prioritizing data quality over parameter tuning is essential. Training Techniques : Full fine-tuning updates all parameters but requires significant computational resources. Techniques like LoRA and QLoRA update only a small number of adapter parameters while keeping the base model frozen. QLoRA further combines 4-bit quantization with LoRA to minimize VRAM usage. Training Parameters : Important parameters to manage include the learning rate (with schedulers), batch size, gradient accumulation, number of epochs, optimizers (e.g., 8-bit AdamW), weight decay, warmup steps, and specific LoRA parameters (rank, alpha, target modules). Distributed Training : Utilize multiple GPUs via frameworks such as DeepSpeed or FSDP. DeepSpeed offers ZeRO optimization stages to improve memory efficiency by partitioning state information. Both frameworks support gradient checkpointing. Monitoring : Keep an eye on metrics like loss curves, learning rate changes, and gradient norms, while addressing issues such as loss spikes or gradient explosions. References: Fine-tune Llama 3.1 Ultra-Efficiently with Unsloth by Maxime Labonne Axolotl \\u2013 Documentation by Wing Lian Mastering LLMs by Hamel Husain LoRA insights by Sebastian Raschka 5. Preference Alignment Preference alignment is a secondary stage in the post-training process that helps fine-tune the model\\u2019s tone and reduce issues like toxicity and hallucinations. Its purpose is to improve performance and usefulness, and it generally involves methods like Direct Preference Optimization (DPO) and Proximal Policy Optimization (PPO). Rejection Sampling : For each prompt, generate multiple responses from the model, then score them to create on-policy data consisting of both chosen and rejected answers. Direct Preference Optimization : This method optimizes the policy by directly increasing the likelihood of chosen responses over rejected ones, without needing a separate reward model. Although it is more computationally efficient than PPO, it may offer a slight decrease in quality. Proximal Policy Optimization : This method iteratively updates the policy to maximize rewards while keeping changes close to the original behavior, using a reward model to score responses and requiring careful hyperparameter tuning (learning rate, batch size, and PPO clip range). Monitoring : Alongside SFT metrics, monitor the margin between chosen and rejected responses and track overall accuracy improvements until reaching a plateau. References: Illustrating RLHF by Hugging Face LLM Training: RLHF and Its Alternatives by Sebastian Raschka Preference Tuning LLMs by Hugging Face Fine-tune Mistral-7b with DPO by Maxime Labonne DPO Wandb logs by Alexander Vishnevskiy 6. Evaluation Evaluating LLMs reliably is a challenging but essential task for refining dataset composition and training settings. It is important to acknowledge Goodhart\\u2019s law: \\u201cWhen a measure becomes a target, it ceases to be a good measure.\\u201d Automated Benchmarks : Use curated datasets and metrics (such as MMLU) to assess performance on specific tasks. This approach works well for concrete tasks but may struggle with abstract capabilities and suffer from data contamination. Human Evaluation : Involve human assessors to prompt models and rate outputs. This method ranges from informal checks to systematic annotations and large-scale community voting (arena) and tends to work best for subjective assessments. Model-based Evaluation : Implement judge or reward models to assess generated responses. Although they often correlate well with human judgment, these models may be biased toward their own outputs. Feedback Signal : Analyze error patterns to identify shortcomings, such as problems following complex instructions, lacking specific knowledge, or being vulnerable to adversarial prompts. Use the feedback to adjust data generation and training parameters. References: Evaluation Guidebook by Cl\\u00e9mentine Fourrier Open LLM Leaderboard by Hugging Face Language Model Evaluation Harness by EleutherAI Lighteval by Hugging Face Chatbot Arena by LMSYS 7. Quantization Quantization converts a model\\u2019s parameters and activations from high precision (e.g., FP32) to lower precision (such as 4 bits) to reduce compute and memory requirements. Base Techniques : Understand the different precisions (FP32, FP16, INT8, etc.) and basic quantization methods like absmax and zero-point techniques. GGUF & llama.cpp : Originally created for CPU-based runs, llama.cpp and the GGUF format are now widely used to run LLMs on consumer hardware. They support the storage of special tokens, vocabulary, and metadata all in one file. GPTQ & AWQ : Methods such as GPTQ / EXL2 and AWQ use layer-wise calibration to maintain performance at very low bitwidths. These techniques adjust scaling dynamically and can selectively bypass or re-center the heaviest parameters. SmoothQuant & ZeroQuant : New methods such as SmoothQuant (which applies quantization-friendly transformations) and compiler-based optimizations like ZeroQuant help alleviate outlier issues before quantization, optimizing data flow and reducing hardware overhead. References: Introduction to Quantization by Maxime Labonne Quantize Llama models with llama.cpp by Maxime Labonne 4-bit LLM Quantization with GPTQ by Maxime Labonne Understanding Activation-Aware Weight Quantization by FriendliAI SmoothQuant on Llama 2 7B by MIT HAN Lab DeepSpeed Model Compression by DeepSpeed 8. New Trends This section covers emerging topics that do not neatly fit into other categories. Some ideas, like model merging and multimodal models, are well established, while others\\u2014such as interpretability or test-time compute scaling\\u2014are more experimental and actively researched. Model Merging : Merging pre-trained models has become a popular technique for boosting performance without additional fine-tuning. The mergekit library implements several popular merging methods, including SLERP, DARE , and TIES . Multimodal Models : Models like CLIP , Stable Diffusion , and LLaVA are designed to process and integrate various types of inputs (text, images, audio, etc.) within a unified embedding space, enabling powerful applications such as text-to-image generation. Interpretability : Mechanistic interpretability approaches, including Sparse Autoencoders (SAEs) and techniques like abliteration, offer insights into the internal operations of LLMs and can allow for behavioral adjustments without retraining. Test-time Compute : Scaling computational resources during inference often requires multiple calls and specialized models (e.g., Process Reward Model (PRM)). Iterative procedures with fine-tuned scoring can markedly enhance performance on complex reasoning tasks. References: Merge LLMs with mergekit by Maxime Labonne Smol Vision by Merve Noyan Large Multimodal Models by Chip Huyen Uncensor any LLM with abliteration by Maxime Labonne Intuitive Explanation of SAEs by Adam Karvonen Scaling test-time compute by Beeching et al. The LLM Engineer This part of the course teaches you how to build production-grade applications powered by LLMs, with a focus on augmenting models and deploying them. 1. Running LLMs Running LLMs can be challenging given their high hardware requirements. Depending on your needs, you might opt to use an API (like GPT-4) or run a model locally. In either case, careful prompting and guidance can greatly enhance output quality and relevance. LLM APIs : APIs provide a convenient way to access LLMs. They are divided between private LLMs (e.g., OpenAI , Google , Anthropic , Cohere ) and open-source LLMs (e.g., OpenRouter , Hugging Face , Together AI ). Open-source LLMs : The Hugging Face Hub is a prime resource for finding LLMs. You can run many of these models in Hugging Face Spaces , or download and operate them locally using tools like LM Studio , llama.cpp , or Ollama . Prompt Engineering : Techniques such as zero-shot prompting, few-shot prompting, chain-of-thought, and ReAct are common. While these methods work better with larger models, they can be adapted for smaller ones. Structuring Outputs : Some tasks require outputs to follow a strict format (such as a JSON format or specific template). Tools such as LMQL , Outlines , and Guidance help ensure the generated text adheres to the required structure. References: Run an LLM locally with LM Studio by Nisha Arya Prompt engineering guide by DAIR.AI Outlines \\u2013 Quickstart LMQL \\u2013 Overview 2. Building a Vector Storage The first step in creating a Retrieval Augmented Generation (RAG) pipeline is establishing a vector storage. This involves loading documents, splitting them into manageable pieces, and then converting key text chunks into vector embeddings for future retrieval. Ingesting Documents : Document loaders can process multiple formats such as PDF, JSON, HTML, and Markdown. They can also pull in data directly from databases and APIs (e.g., GitHub, Reddit, Google Drive). Splitting Documents : Text splitters divide documents into smaller, semantically relevant chunks. Instead of a fixed character count, splitting by headers or recursively\\u2014while preserving metadata\\u2014often yields better results. Embedding Models : These models transform text into vector representations, enabling a more nuanced semantic interpretation that is essential for effective search. Vector Databases : Databases like Chroma , Pinecone , Milvus , FAISS , and Annoy are designed for storing embeddings, allowing for fast similarity-based retrieval. References: LangChain \\u2013 Text splitters Sentence Transformers library MTEB Leaderboard The Top 5 Vector Databases by Moez Ali 3. Retrieval Augmented Generation Retrieval Augmented Generation (RAG) enhances LLM outputs by using relevant contextual documents fetched from a vector database, thus improving answer accuracy without needing additional fine-tuning. Orchestrators : Tools like LangChain , LlamaIndex , and FastRAG connect LLMs to tools, databases, and memory systems, extending their functionality. Retrievers : Since user queries may not be optimized for search, techniques such as multi-query retrievers or HyDE can reformulate queries to improve retrieval performance. Memory : To maintain context over a conversation, LLMs use a history buffer that can be enhanced with summarization techniques or integrated with vector stores via RAG. Evaluation : It is crucial to assess both the document retrieval process (precision and recall) and the generation stage (faithfulness and relevancy). Tools like Ragas and DeepEval can assist in these evaluations. References: Llamaindex \\u2013 High-level concepts Pinecone \\u2013 Retrieval Augmentation LangChain \\u2013 Q&A with RAG LangChain \\u2013 Memory types RAG pipeline \\u2013 Metrics 4. Advanced RAG In real-world scenarios, you may need to develop more complex pipelines involving SQL or graph databases, as well as systems that automatically select appropriate tools and APIs to enhance the baseline RAG setup. Query Construction : For structured data stored in databases, you need to translate user instructions into appropriate query languages like SQL or Cypher. Agents and Tools : LLM agents can automatically choose the most suitable tools\\u2014ranging from simple web searches (e.g., Google, Wikipedia) to complex systems (e.g., Python interpreters, Jira)\\u2014to answer queries. Post-Processing : Enhance the overall relevance of retrieved documents using re-ranking methods, RAG-fusion , or classification techniques. Program LLMs : Frameworks like DSPy allow you to fine-tune prompts and model parameters programmatically based on automated evaluations. References: LangChain \\u2013 Query Construction LangChain \\u2013 SQL Pinecone \\u2013 LLM agents LLM Powered Autonomous Agents by Lilian Weng LangChain \\u2013 OpenAI\\u2019s RAG DSPy in 8 Steps 5. Inference Optimization Since generating text is computationally intensive, several techniques exist to maximize throughput and reduce inference costs alongside quantization. Flash Attention : Optimizes the attention mechanism by reducing its complexity from quadratic to linear, thereby speeding up both training and inference. Key-value Cache : Learn about the key-value cache and enhancements like Multi-Query Attention (MQA) and Grouped-Query Attention (GQA). Speculative Decoding : Use a smaller model to produce draft outputs that are later refined by a larger model, thus accelerating text generation. References: GPU Inference by Hugging Face LLM Inference by Databricks Optimizing LLMs for Speed and Memory by Hugging Face Assisted Generation by Hugging Face 6. Deploying LLMs Deploying LLMs, especially at scale, is complex and may require multiple GPU clusters. However, demos or local applications often have simpler requirements. Local Deployment : Open-source LLMs offer privacy advantages over private models. Solutions such as LM Studio , Ollama , oobabooga , and kobold.cpp facilitate local deployment. Demo Deployment : Tools like Gradio and Streamlit are excellent for prototyping apps and sharing demos. They are also easy to host online (for example, on Hugging Face Spaces ). Server Deployment : Running LLMs at scale often demands cloud infrastructure (or on-prem solutions) and specialized frameworks such as TGI or vLLM . Edge Deployment : In resource-constrained environments, frameworks like MLC LLM and mnn-llm enable deployment on web browsers, Android, and iOS. References: Streamlit \\u2013 Build a basic LLM app by Streamlit HF LLM Inference Container by Hugging Face Philschmid blog by Philipp Schmid Optimizing Latency by Hamel Husain 7. Securing LLMs LLM applications bring their own unique security challenges in addition to standard software vulnerabilities. Prompt Hacking : This includes issues like prompt injection (where unwanted instructions hijack the model), data/prompt leaking (extracting the original prompt or training data), and jailbreaking (bypassing the model\\u2019s safety features). Backdoors : These attacks can target training data by poisoning it with false or malicious content, or by introducing hidden triggers that alter model behavior during inference. Defensive Measures : Protect your LLM applications by testing them for vulnerabilities using techniques such as red teaming and tools like garak , while monitoring in production with frameworks like langfuse . References: OWASP LLM Top 10 by HEGO Wiki Prompt Injection Primer by Joseph Thacker LLM Security by @llm_sec Red teaming LLMs by Microsoft \\u2190 Previous Next \\u2192\", \"score\": 5, \"type\": \"image\", \"group_id\": 1, \"format\": \"jpg\", \"width\": 300}, {\"src\": \"https://originshq.com/wp-content/uploads/2025/01/top_learning_resource_ai_llm_in_2025-1024x576.jpg\", \"alt\": \"Top AI/LLM learning resource in 2025\", \"desc\": \"Table of Contents \\ud83d\\udcdd Notebooks Tools Fine-tuning Quantization Other LLM Fundamentals 1. Mathematics for Machine Learning 2. Python for Machine Learning 3. Neural Networks 4. Natural Language Processing (NLP) The LLM Scientist 1. The LLM Architecture 2. Pre-training Models 3. Post-training Datasets 4. Supervised Fine-Tuning 5. Preference Alignment 6. Evaluation 7. Quantization 8. New Trends The LLM Engineer 1. Running LLMs 2. Building a Vector Storage 3. Retrieval Augmented Generation 4. Advanced RAG 5. Inference Optimization 6. Deploying LLMs 7. Securing LLMs Seeking Experts for Implementing AI ? The Blog is organized into three main segments: LLM Fundamentals (optional) \\u2013 Covers essential topics such as mathematics, Python, and neural networks. The LLM Scientist \\u2013 Concentrates on creating the best-performing LLMs using state-of-the-art techniques. The LLM Engineer \\u2013 Focuses on building applications based on LLMs and deploying them. \\ud83d\\udcdd Notebooks Below is a collection of notebooks and articles dedicated to LLMs. Tools Notebook Name Description Notebook \\ud83e\\uddd0 LLM AutoEval Evaluate your LLMs automatically using RunPod. Notebook \\ud83e\\udd71 LazyMergekit Merge models effortlessly using MergeKit with a single click. Notebook \\ud83e\\udd8e LazyAxolotl Fine-tune models in the cloud with Axolotl in just one click. Notebook \\u26a1 AutoQuant Quantize LLMs into GGUF, GPTQ, EXL2, AWQ, and HQQ formats in one click. Notebook \\ud83c\\udf33 Model Family Tree Visualize the lineage of merged models. Notebook \\ud83d\\ude80 ZeroSpace Instantly create a Gradio chat interface using a free ZeroGPU. Notebook Fine-tuning Notebook Name Description Article Notebook Fine-tune Llama 3.1 with Unsloth Perform ultra-efficient supervised fine-tuning in Google Colab. Article Notebook Fine-tune Llama 3 with ORPO Achieve cheaper and faster fine-tuning in a single stage with ORPO. Article Notebook Fine-tune Mistral-7b with DPO Enhance the performance of supervised fine-tuned models using DPO. Article Notebook Fine-tune Mistral-7b with QLoRA Supervised fine-tuning of Mistral-7b in a free-tier Google Colab using TRL. Notebook Fine-tune CodeLlama using Axolotl A comprehensive guide to fine-tune with the state-of-the-art Axolotl tool. Article Notebook Fine-tune Llama 2 with QLoRA A step-by-step guide to supervised fine-tuning of Llama 2 in Google Colab. Article Notebook Quantization Notebook Name Description Article Notebook Introduction to Quantization An overview of optimizing large language models using 8-bit quantization. Article Notebook 4-bit Quantization using GPTQ Learn to quantize your open-source LLMs for consumer hardware using GPTQ. Article Notebook Quantization with GGUF and llama.cpp Quantize Llama 2 models with llama.cpp and upload their GGUF versions to the HF Hub. Article Notebook ExLlamaV2: The Fastest Library to Run LLMs Quantize and run EXL2 models, then upload them to the HF Hub. Article Notebook Other Notebook Name Description Article Notebook Merge LLMs with MergeKit Easily create your own models without needing a GPU. Article Notebook Create MoEs with MergeKit Combine multiple experts into a single frankenMoE. Article Notebook Uncensor any LLM with abliteration Fine-tuning strategies without retraining the model. Article Notebook Improve ChatGPT with Knowledge Graphs Augment ChatGPT\\u2019s responses using knowledge graphs. Article Notebook Decoding Strategies in Large Language Models A comprehensive guide covering text generation methods from beam search to nucleus sampling. Article Notebook LLM Fundamentals This section provides core knowledge about mathematics, Python, and neural networks. While you may not begin here if you already have the basics, feel free to refer back as needed. 1. Mathematics for Machine Learning Before diving deep into machine learning, it is essential to master the fundamental mathematical concepts that underpin these algorithms: Linear Algebra : Crucial for many algorithms, particularly in deep learning. Topics include vectors, matrices, determinants, eigenvalues and eigenvectors, vector spaces, and linear transformations. Calculus : Needed to optimize continuous functions. Learn about derivatives, integrals, limits, series, multivariable calculus, and gradient concepts. Probability and Statistics : Key for understanding model behavior and data prediction. Essential topics include probability theory, random variables, distributions, expectations, variance, covariance, correlation, hypothesis testing, confidence intervals, maximum likelihood estimation, and Bayesian inference. Resources: 3Blue1Brown \\u2013 The Essence of Linear Algebra StatQuest with Josh Starmer \\u2013 Statistics Fundamentals AP Statistics Intuition by Ms Aerin Immersive Linear Algebra Khan Academy \\u2013 Linear Algebra Khan Academy \\u2013 Calculus Khan Academy \\u2013 Probability and Statistics 2. Python for Machine Learning Python is a flexible and powerful language, especially suited for machine learning because of its clear syntax and extensive ecosystem. Python Basics : Understand basic syntax, data types, error handling, and object-oriented programming. Data Science Libraries : Gain experience with NumPy for numerical operations; Pandas for data manipulation; and Matplotlib/Seaborn for visualizations. Data Preprocessing : Learn techniques such as feature scaling, normalization, handling missing values, outlier detection, encoding categorical data, and data splitting. Machine Learning Libraries : Familiarize yourself with Scikit-learn, which offers numerous supervised and unsupervised algorithms. Understand implementations of linear regression, logistic regression, decision trees, random forests, k-nearest neighbors, K-means clustering, and dimensionality reduction methods like PCA and t-SNE. Resources: Real Python freeCodeCamp \\u2013 Learn Python Python Data Science Handbook freeCodeCamp \\u2013 Machine Learning for Everybody Udacity \\u2013 Intro to Machine Learning 3. Neural Networks Neural networks form the backbone of many modern deep learning models. It\\u2019s important to understand how they work and are built: Fundamentals : Know the basic structure including layers, weights, biases, and activation functions (sigmoid, tanh, ReLU, etc.). Training and Optimization : Get to know backpropagation, common loss functions (MSE, Cross-Entropy), and optimization algorithms (Gradient Descent, SGD, RMSprop, Adam). Overfitting : Understand what overfitting means and study regularization techniques such as dropout, L1/L2 regularization, early stopping, and data augmentation. Implementing a Multilayer Perceptron (MLP) : Build an MLP (a fully connected network) using frameworks like PyTorch. Resources: 3Blue1Brown \\u2013 But what is a Neural Network? freeCodeCamp \\u2013 Deep Learning Crash Course Fast.ai \\u2013 Practical Deep Learning Patrick Loeber \\u2013 PyTorch Tutorials 4. Natural Language Processing (NLP) NLP is an exciting field that connects human language with machine comprehension. It ranges from basic text processing to capturing intricate linguistic nuances. Text Preprocessing : Understand tokenization (dividing text into words or sentences), stemming (reducing words to their roots), lemmatization (context-aware reduction), and stop word removal. Feature Extraction Techniques : Learn how to transform textual data for machine learning algorithms using techniques like Bag-of-Words (BoW), TF-IDF, and n-grams. Word Embeddings : Study methods such as Word2Vec, GloVe, and FastText which allow words with similar meanings to have similar vector representations. Recurrent Neural Networks (RNNs) : Learn how RNNs are designed for sequential data and explore variants like LSTMs and GRUs, which capture long-term dependencies. Resources: Lena Voita \\u2013 Word Embeddings RealPython \\u2013 NLP with spaCy in Python Kaggle \\u2013 NLP Guide Jay Alammar \\u2013 The Illustration Word2Vec Jake Tae \\u2013 PyTorch RNN from Scratch colah\\u2019s blog \\u2013 Understanding LSTM Networks The LLM Scientist This section is designed to help you learn how to build the most effective LLMs using the latest methodologies. 1. The LLM Architecture You don\\u2019t need an exhaustive understanding of the Transformer architecture, but it is important to know the major steps in modern LLMs: converting text into numeric tokens, processing these tokens with layers (including attention mechanisms), and using various sampling strategies to generate text. Architectural Overview : Trace the evolution from encoder-decoder Transformers to decoder-only structures like GPT, which are fundamental to modern LLMs. Understand how these models process and generate text at a high level. Tokenization : Learn the principles behind tokenization and how it transforms text into numerical data that models can process. Investigate different tokenization strategies and their effects on performance and output quality. Attention Mechanisms : Master the concept of attention, particularly self-attention and its variants, and see how they help models deal with long-range dependencies and maintain contextual integrity. Sampling Techniques : Compare deterministic methods (e.g., greedy search, beam search) to probabilistic methods (e.g., temperature sampling, nucleus sampling) and evaluate the trade-offs involved. References: Visual intro to Transformers by 3Blue1Brown LLM Visualization by Brendan Bycroft nanoGPT by Andrej Karpathy (includes a tokenization video: here ) Attention? Attention! by Lilian Weng Decoding Strategies in LLMs by Maxime Labonne 2. Pre-training Models Pre-training LLMs is an expensive and resource-intensive process. Although this course does not primarily focus on pre-training, understanding the process, particularly regarding data handling and model parameters, is crucial. For smaller-scale hobbyist projects, pre-training on models with fewer than 1B parameters is feasible. Data Preparation : Pre-training requires vast datasets (for example, Llama 3.1 was trained on 15 trillion tokens), which must be curated, cleaned, deduplicated, and tokenized. Modern pipelines include extensive quality filtering. Distributed Training : Explore techniques such as data parallelism (distributing batches), pipeline parallelism (distributing layers), and tensor parallelism (splitting operations). These require effective network communication and memory management across GPU clusters. Training Optimization : Utilize adaptive learning rate schedules with warm-up, gradient clipping and normalization, mixed-precision training, and modern optimizers (AdamW, Lion) with well-tuned hyperparameters. Monitoring : Implement dashboards and logging to track metrics (loss, gradients, GPU usage) and profile performance to identify computational and communication bottlenecks. References: FineWeb by Penedo et al. RedPajama v2 by Weber et al. nanotron by Hugging Face (used for SmolLM2 ) Parallel Training by Chenyan Xiong Distributed Training by Duan et al. OLMo 2 by AI2 LLM360 by LLM360 3. Post-training Datasets Post-training datasets are organized with clear structures including instructions paired with answers (supervised fine-tuning) or instructions paired with chosen/rejected responses (preference alignment). Given that conversational datasets are less common compared to raw pre-training data, additional processing is often needed to enhance sample accuracy, diversity, and complexity. More details can be found in the \\ud83d\\udcbe LLM Datasets repository. Storage & Chat Templates : Due to their conversational nature, these datasets are stored in formats such as ShareGPT or OpenAI/HF. These are then mapped to chat templates like ChatML or Alpaca for training. Synthetic Data Generation : Use frontier models like GPT-4o to create instruction-response pairs from seed data. This method offers flexibility and scalability, with considerations for diverse seed tasks and effective system prompts. Data Enhancement : Enhance your samples with techniques including verified outputs (using unit tests/solvers), generating multiple answers with rejection sampling, Auto-Evol , Chain-of-Thought, Branch-Solve-Merge, persona-based approaches, and more. Quality Filtering : Traditional filtering methods involve rule-based approaches, duplicate removal (using MinHash or embeddings), and n-gram decontamination, with reward models and judge LLMs providing additional quality control. References: Synthetic Data Generator by Argilla LLM Datasets by Maxime Labonne NeMo-Curator by Nvidia Distilabel by Argilla Semhash by MinishLab Chat Template by Hugging Face 4. Supervised Fine-Tuning Supervised Fine-Tuning (SFT) transforms base models into helpful assistants capable of following instructions and structuring answers effectively. Although SFT can be used to introduce new knowledge, its ability to completely learn a new language is limited. Thus, prioritizing data quality over parameter tuning is essential. Training Techniques : Full fine-tuning updates all parameters but requires significant computational resources. Techniques like LoRA and QLoRA update only a small number of adapter parameters while keeping the base model frozen. QLoRA further combines 4-bit quantization with LoRA to minimize VRAM usage. Training Parameters : Important parameters to manage include the learning rate (with schedulers), batch size, gradient accumulation, number of epochs, optimizers (e.g., 8-bit AdamW), weight decay, warmup steps, and specific LoRA parameters (rank, alpha, target modules). Distributed Training : Utilize multiple GPUs via frameworks such as DeepSpeed or FSDP. DeepSpeed offers ZeRO optimization stages to improve memory efficiency by partitioning state information. Both frameworks support gradient checkpointing. Monitoring : Keep an eye on metrics like loss curves, learning rate changes, and gradient norms, while addressing issues such as loss spikes or gradient explosions. References: Fine-tune Llama 3.1 Ultra-Efficiently with Unsloth by Maxime Labonne Axolotl \\u2013 Documentation by Wing Lian Mastering LLMs by Hamel Husain LoRA insights by Sebastian Raschka 5. Preference Alignment Preference alignment is a secondary stage in the post-training process that helps fine-tune the model\\u2019s tone and reduce issues like toxicity and hallucinations. Its purpose is to improve performance and usefulness, and it generally involves methods like Direct Preference Optimization (DPO) and Proximal Policy Optimization (PPO). Rejection Sampling : For each prompt, generate multiple responses from the model, then score them to create on-policy data consisting of both chosen and rejected answers. Direct Preference Optimization : This method optimizes the policy by directly increasing the likelihood of chosen responses over rejected ones, without needing a separate reward model. Although it is more computationally efficient than PPO, it may offer a slight decrease in quality. Proximal Policy Optimization : This method iteratively updates the policy to maximize rewards while keeping changes close to the original behavior, using a reward model to score responses and requiring careful hyperparameter tuning (learning rate, batch size, and PPO clip range). Monitoring : Alongside SFT metrics, monitor the margin between chosen and rejected responses and track overall accuracy improvements until reaching a plateau. References: Illustrating RLHF by Hugging Face LLM Training: RLHF and Its Alternatives by Sebastian Raschka Preference Tuning LLMs by Hugging Face Fine-tune Mistral-7b with DPO by Maxime Labonne DPO Wandb logs by Alexander Vishnevskiy 6. Evaluation Evaluating LLMs reliably is a challenging but essential task for refining dataset composition and training settings. It is important to acknowledge Goodhart\\u2019s law: \\u201cWhen a measure becomes a target, it ceases to be a good measure.\\u201d Automated Benchmarks : Use curated datasets and metrics (such as MMLU) to assess performance on specific tasks. This approach works well for concrete tasks but may struggle with abstract capabilities and suffer from data contamination. Human Evaluation : Involve human assessors to prompt models and rate outputs. This method ranges from informal checks to systematic annotations and large-scale community voting (arena) and tends to work best for subjective assessments. Model-based Evaluation : Implement judge or reward models to assess generated responses. Although they often correlate well with human judgment, these models may be biased toward their own outputs. Feedback Signal : Analyze error patterns to identify shortcomings, such as problems following complex instructions, lacking specific knowledge, or being vulnerable to adversarial prompts. Use the feedback to adjust data generation and training parameters. References: Evaluation Guidebook by Cl\\u00e9mentine Fourrier Open LLM Leaderboard by Hugging Face Language Model Evaluation Harness by EleutherAI Lighteval by Hugging Face Chatbot Arena by LMSYS 7. Quantization Quantization converts a model\\u2019s parameters and activations from high precision (e.g., FP32) to lower precision (such as 4 bits) to reduce compute and memory requirements. Base Techniques : Understand the different precisions (FP32, FP16, INT8, etc.) and basic quantization methods like absmax and zero-point techniques. GGUF & llama.cpp : Originally created for CPU-based runs, llama.cpp and the GGUF format are now widely used to run LLMs on consumer hardware. They support the storage of special tokens, vocabulary, and metadata all in one file. GPTQ & AWQ : Methods such as GPTQ / EXL2 and AWQ use layer-wise calibration to maintain performance at very low bitwidths. These techniques adjust scaling dynamically and can selectively bypass or re-center the heaviest parameters. SmoothQuant & ZeroQuant : New methods such as SmoothQuant (which applies quantization-friendly transformations) and compiler-based optimizations like ZeroQuant help alleviate outlier issues before quantization, optimizing data flow and reducing hardware overhead. References: Introduction to Quantization by Maxime Labonne Quantize Llama models with llama.cpp by Maxime Labonne 4-bit LLM Quantization with GPTQ by Maxime Labonne Understanding Activation-Aware Weight Quantization by FriendliAI SmoothQuant on Llama 2 7B by MIT HAN Lab DeepSpeed Model Compression by DeepSpeed 8. New Trends This section covers emerging topics that do not neatly fit into other categories. Some ideas, like model merging and multimodal models, are well established, while others\\u2014such as interpretability or test-time compute scaling\\u2014are more experimental and actively researched. Model Merging : Merging pre-trained models has become a popular technique for boosting performance without additional fine-tuning. The mergekit library implements several popular merging methods, including SLERP, DARE , and TIES . Multimodal Models : Models like CLIP , Stable Diffusion , and LLaVA are designed to process and integrate various types of inputs (text, images, audio, etc.) within a unified embedding space, enabling powerful applications such as text-to-image generation. Interpretability : Mechanistic interpretability approaches, including Sparse Autoencoders (SAEs) and techniques like abliteration, offer insights into the internal operations of LLMs and can allow for behavioral adjustments without retraining. Test-time Compute : Scaling computational resources during inference often requires multiple calls and specialized models (e.g., Process Reward Model (PRM)). Iterative procedures with fine-tuned scoring can markedly enhance performance on complex reasoning tasks. References: Merge LLMs with mergekit by Maxime Labonne Smol Vision by Merve Noyan Large Multimodal Models by Chip Huyen Uncensor any LLM with abliteration by Maxime Labonne Intuitive Explanation of SAEs by Adam Karvonen Scaling test-time compute by Beeching et al. The LLM Engineer This part of the course teaches you how to build production-grade applications powered by LLMs, with a focus on augmenting models and deploying them. 1. Running LLMs Running LLMs can be challenging given their high hardware requirements. Depending on your needs, you might opt to use an API (like GPT-4) or run a model locally. In either case, careful prompting and guidance can greatly enhance output quality and relevance. LLM APIs : APIs provide a convenient way to access LLMs. They are divided between private LLMs (e.g., OpenAI , Google , Anthropic , Cohere ) and open-source LLMs (e.g., OpenRouter , Hugging Face , Together AI ). Open-source LLMs : The Hugging Face Hub is a prime resource for finding LLMs. You can run many of these models in Hugging Face Spaces , or download and operate them locally using tools like LM Studio , llama.cpp , or Ollama . Prompt Engineering : Techniques such as zero-shot prompting, few-shot prompting, chain-of-thought, and ReAct are common. While these methods work better with larger models, they can be adapted for smaller ones. Structuring Outputs : Some tasks require outputs to follow a strict format (such as a JSON format or specific template). Tools such as LMQL , Outlines , and Guidance help ensure the generated text adheres to the required structure. References: Run an LLM locally with LM Studio by Nisha Arya Prompt engineering guide by DAIR.AI Outlines \\u2013 Quickstart LMQL \\u2013 Overview 2. Building a Vector Storage The first step in creating a Retrieval Augmented Generation (RAG) pipeline is establishing a vector storage. This involves loading documents, splitting them into manageable pieces, and then converting key text chunks into vector embeddings for future retrieval. Ingesting Documents : Document loaders can process multiple formats such as PDF, JSON, HTML, and Markdown. They can also pull in data directly from databases and APIs (e.g., GitHub, Reddit, Google Drive). Splitting Documents : Text splitters divide documents into smaller, semantically relevant chunks. Instead of a fixed character count, splitting by headers or recursively\\u2014while preserving metadata\\u2014often yields better results. Embedding Models : These models transform text into vector representations, enabling a more nuanced semantic interpretation that is essential for effective search. Vector Databases : Databases like Chroma , Pinecone , Milvus , FAISS , and Annoy are designed for storing embeddings, allowing for fast similarity-based retrieval. References: LangChain \\u2013 Text splitters Sentence Transformers library MTEB Leaderboard The Top 5 Vector Databases by Moez Ali 3. Retrieval Augmented Generation Retrieval Augmented Generation (RAG) enhances LLM outputs by using relevant contextual documents fetched from a vector database, thus improving answer accuracy without needing additional fine-tuning. Orchestrators : Tools like LangChain , LlamaIndex , and FastRAG connect LLMs to tools, databases, and memory systems, extending their functionality. Retrievers : Since user queries may not be optimized for search, techniques such as multi-query retrievers or HyDE can reformulate queries to improve retrieval performance. Memory : To maintain context over a conversation, LLMs use a history buffer that can be enhanced with summarization techniques or integrated with vector stores via RAG. Evaluation : It is crucial to assess both the document retrieval process (precision and recall) and the generation stage (faithfulness and relevancy). Tools like Ragas and DeepEval can assist in these evaluations. References: Llamaindex \\u2013 High-level concepts Pinecone \\u2013 Retrieval Augmentation LangChain \\u2013 Q&A with RAG LangChain \\u2013 Memory types RAG pipeline \\u2013 Metrics 4. Advanced RAG In real-world scenarios, you may need to develop more complex pipelines involving SQL or graph databases, as well as systems that automatically select appropriate tools and APIs to enhance the baseline RAG setup. Query Construction : For structured data stored in databases, you need to translate user instructions into appropriate query languages like SQL or Cypher. Agents and Tools : LLM agents can automatically choose the most suitable tools\\u2014ranging from simple web searches (e.g., Google, Wikipedia) to complex systems (e.g., Python interpreters, Jira)\\u2014to answer queries. Post-Processing : Enhance the overall relevance of retrieved documents using re-ranking methods, RAG-fusion , or classification techniques. Program LLMs : Frameworks like DSPy allow you to fine-tune prompts and model parameters programmatically based on automated evaluations. References: LangChain \\u2013 Query Construction LangChain \\u2013 SQL Pinecone \\u2013 LLM agents LLM Powered Autonomous Agents by Lilian Weng LangChain \\u2013 OpenAI\\u2019s RAG DSPy in 8 Steps 5. Inference Optimization Since generating text is computationally intensive, several techniques exist to maximize throughput and reduce inference costs alongside quantization. Flash Attention : Optimizes the attention mechanism by reducing its complexity from quadratic to linear, thereby speeding up both training and inference. Key-value Cache : Learn about the key-value cache and enhancements like Multi-Query Attention (MQA) and Grouped-Query Attention (GQA). Speculative Decoding : Use a smaller model to produce draft outputs that are later refined by a larger model, thus accelerating text generation. References: GPU Inference by Hugging Face LLM Inference by Databricks Optimizing LLMs for Speed and Memory by Hugging Face Assisted Generation by Hugging Face 6. Deploying LLMs Deploying LLMs, especially at scale, is complex and may require multiple GPU clusters. However, demos or local applications often have simpler requirements. Local Deployment : Open-source LLMs offer privacy advantages over private models. Solutions such as LM Studio , Ollama , oobabooga , and kobold.cpp facilitate local deployment. Demo Deployment : Tools like Gradio and Streamlit are excellent for prototyping apps and sharing demos. They are also easy to host online (for example, on Hugging Face Spaces ). Server Deployment : Running LLMs at scale often demands cloud infrastructure (or on-prem solutions) and specialized frameworks such as TGI or vLLM . Edge Deployment : In resource-constrained environments, frameworks like MLC LLM and mnn-llm enable deployment on web browsers, Android, and iOS. References: Streamlit \\u2013 Build a basic LLM app by Streamlit HF LLM Inference Container by Hugging Face Philschmid blog by Philipp Schmid Optimizing Latency by Hamel Husain 7. Securing LLMs LLM applications bring their own unique security challenges in addition to standard software vulnerabilities. Prompt Hacking : This includes issues like prompt injection (where unwanted instructions hijack the model), data/prompt leaking (extracting the original prompt or training data), and jailbreaking (bypassing the model\\u2019s safety features). Backdoors : These attacks can target training data by poisoning it with false or malicious content, or by introducing hidden triggers that alter model behavior during inference. Defensive Measures : Protect your LLM applications by testing them for vulnerabilities using techniques such as red teaming and tools like garak , while monitoring in production with frameworks like langfuse . References: OWASP LLM Top 10 by HEGO Wiki Prompt Injection Primer by Joseph Thacker LLM Security by @llm_sec Red teaming LLMs by Microsoft \\u2190 Previous Next \\u2192\", \"score\": 5, \"type\": \"image\", \"group_id\": 1, \"format\": \"jpg\", \"width\": 1024}, {\"src\": \"https://originshq.com/wp-content/uploads/2025/01/top_learning_resource_ai_llm_in_2025-768x432.jpg\", \"alt\": \"Top AI/LLM learning resource in 2025\", \"desc\": \"Table of Contents \\ud83d\\udcdd Notebooks Tools Fine-tuning Quantization Other LLM Fundamentals 1. Mathematics for Machine Learning 2. Python for Machine Learning 3. Neural Networks 4. Natural Language Processing (NLP) The LLM Scientist 1. The LLM Architecture 2. Pre-training Models 3. Post-training Datasets 4. Supervised Fine-Tuning 5. Preference Alignment 6. Evaluation 7. Quantization 8. New Trends The LLM Engineer 1. Running LLMs 2. Building a Vector Storage 3. Retrieval Augmented Generation 4. Advanced RAG 5. Inference Optimization 6. Deploying LLMs 7. Securing LLMs Seeking Experts for Implementing AI ? The Blog is organized into three main segments: LLM Fundamentals (optional) \\u2013 Covers essential topics such as mathematics, Python, and neural networks. The LLM Scientist \\u2013 Concentrates on creating the best-performing LLMs using state-of-the-art techniques. The LLM Engineer \\u2013 Focuses on building applications based on LLMs and deploying them. \\ud83d\\udcdd Notebooks Below is a collection of notebooks and articles dedicated to LLMs. Tools Notebook Name Description Notebook \\ud83e\\uddd0 LLM AutoEval Evaluate your LLMs automatically using RunPod. Notebook \\ud83e\\udd71 LazyMergekit Merge models effortlessly using MergeKit with a single click. Notebook \\ud83e\\udd8e LazyAxolotl Fine-tune models in the cloud with Axolotl in just one click. Notebook \\u26a1 AutoQuant Quantize LLMs into GGUF, GPTQ, EXL2, AWQ, and HQQ formats in one click. Notebook \\ud83c\\udf33 Model Family Tree Visualize the lineage of merged models. Notebook \\ud83d\\ude80 ZeroSpace Instantly create a Gradio chat interface using a free ZeroGPU. Notebook Fine-tuning Notebook Name Description Article Notebook Fine-tune Llama 3.1 with Unsloth Perform ultra-efficient supervised fine-tuning in Google Colab. Article Notebook Fine-tune Llama 3 with ORPO Achieve cheaper and faster fine-tuning in a single stage with ORPO. Article Notebook Fine-tune Mistral-7b with DPO Enhance the performance of supervised fine-tuned models using DPO. Article Notebook Fine-tune Mistral-7b with QLoRA Supervised fine-tuning of Mistral-7b in a free-tier Google Colab using TRL. Notebook Fine-tune CodeLlama using Axolotl A comprehensive guide to fine-tune with the state-of-the-art Axolotl tool. Article Notebook Fine-tune Llama 2 with QLoRA A step-by-step guide to supervised fine-tuning of Llama 2 in Google Colab. Article Notebook Quantization Notebook Name Description Article Notebook Introduction to Quantization An overview of optimizing large language models using 8-bit quantization. Article Notebook 4-bit Quantization using GPTQ Learn to quantize your open-source LLMs for consumer hardware using GPTQ. Article Notebook Quantization with GGUF and llama.cpp Quantize Llama 2 models with llama.cpp and upload their GGUF versions to the HF Hub. Article Notebook ExLlamaV2: The Fastest Library to Run LLMs Quantize and run EXL2 models, then upload them to the HF Hub. Article Notebook Other Notebook Name Description Article Notebook Merge LLMs with MergeKit Easily create your own models without needing a GPU. Article Notebook Create MoEs with MergeKit Combine multiple experts into a single frankenMoE. Article Notebook Uncensor any LLM with abliteration Fine-tuning strategies without retraining the model. Article Notebook Improve ChatGPT with Knowledge Graphs Augment ChatGPT\\u2019s responses using knowledge graphs. Article Notebook Decoding Strategies in Large Language Models A comprehensive guide covering text generation methods from beam search to nucleus sampling. Article Notebook LLM Fundamentals This section provides core knowledge about mathematics, Python, and neural networks. While you may not begin here if you already have the basics, feel free to refer back as needed. 1. Mathematics for Machine Learning Before diving deep into machine learning, it is essential to master the fundamental mathematical concepts that underpin these algorithms: Linear Algebra : Crucial for many algorithms, particularly in deep learning. Topics include vectors, matrices, determinants, eigenvalues and eigenvectors, vector spaces, and linear transformations. Calculus : Needed to optimize continuous functions. Learn about derivatives, integrals, limits, series, multivariable calculus, and gradient concepts. Probability and Statistics : Key for understanding model behavior and data prediction. Essential topics include probability theory, random variables, distributions, expectations, variance, covariance, correlation, hypothesis testing, confidence intervals, maximum likelihood estimation, and Bayesian inference. Resources: 3Blue1Brown \\u2013 The Essence of Linear Algebra StatQuest with Josh Starmer \\u2013 Statistics Fundamentals AP Statistics Intuition by Ms Aerin Immersive Linear Algebra Khan Academy \\u2013 Linear Algebra Khan Academy \\u2013 Calculus Khan Academy \\u2013 Probability and Statistics 2. Python for Machine Learning Python is a flexible and powerful language, especially suited for machine learning because of its clear syntax and extensive ecosystem. Python Basics : Understand basic syntax, data types, error handling, and object-oriented programming. Data Science Libraries : Gain experience with NumPy for numerical operations; Pandas for data manipulation; and Matplotlib/Seaborn for visualizations. Data Preprocessing : Learn techniques such as feature scaling, normalization, handling missing values, outlier detection, encoding categorical data, and data splitting. Machine Learning Libraries : Familiarize yourself with Scikit-learn, which offers numerous supervised and unsupervised algorithms. Understand implementations of linear regression, logistic regression, decision trees, random forests, k-nearest neighbors, K-means clustering, and dimensionality reduction methods like PCA and t-SNE. Resources: Real Python freeCodeCamp \\u2013 Learn Python Python Data Science Handbook freeCodeCamp \\u2013 Machine Learning for Everybody Udacity \\u2013 Intro to Machine Learning 3. Neural Networks Neural networks form the backbone of many modern deep learning models. It\\u2019s important to understand how they work and are built: Fundamentals : Know the basic structure including layers, weights, biases, and activation functions (sigmoid, tanh, ReLU, etc.). Training and Optimization : Get to know backpropagation, common loss functions (MSE, Cross-Entropy), and optimization algorithms (Gradient Descent, SGD, RMSprop, Adam). Overfitting : Understand what overfitting means and study regularization techniques such as dropout, L1/L2 regularization, early stopping, and data augmentation. Implementing a Multilayer Perceptron (MLP) : Build an MLP (a fully connected network) using frameworks like PyTorch. Resources: 3Blue1Brown \\u2013 But what is a Neural Network? freeCodeCamp \\u2013 Deep Learning Crash Course Fast.ai \\u2013 Practical Deep Learning Patrick Loeber \\u2013 PyTorch Tutorials 4. Natural Language Processing (NLP) NLP is an exciting field that connects human language with machine comprehension. It ranges from basic text processing to capturing intricate linguistic nuances. Text Preprocessing : Understand tokenization (dividing text into words or sentences), stemming (reducing words to their roots), lemmatization (context-aware reduction), and stop word removal. Feature Extraction Techniques : Learn how to transform textual data for machine learning algorithms using techniques like Bag-of-Words (BoW), TF-IDF, and n-grams. Word Embeddings : Study methods such as Word2Vec, GloVe, and FastText which allow words with similar meanings to have similar vector representations. Recurrent Neural Networks (RNNs) : Learn how RNNs are designed for sequential data and explore variants like LSTMs and GRUs, which capture long-term dependencies. Resources: Lena Voita \\u2013 Word Embeddings RealPython \\u2013 NLP with spaCy in Python Kaggle \\u2013 NLP Guide Jay Alammar \\u2013 The Illustration Word2Vec Jake Tae \\u2013 PyTorch RNN from Scratch colah\\u2019s blog \\u2013 Understanding LSTM Networks The LLM Scientist This section is designed to help you learn how to build the most effective LLMs using the latest methodologies. 1. The LLM Architecture You don\\u2019t need an exhaustive understanding of the Transformer architecture, but it is important to know the major steps in modern LLMs: converting text into numeric tokens, processing these tokens with layers (including attention mechanisms), and using various sampling strategies to generate text. Architectural Overview : Trace the evolution from encoder-decoder Transformers to decoder-only structures like GPT, which are fundamental to modern LLMs. Understand how these models process and generate text at a high level. Tokenization : Learn the principles behind tokenization and how it transforms text into numerical data that models can process. Investigate different tokenization strategies and their effects on performance and output quality. Attention Mechanisms : Master the concept of attention, particularly self-attention and its variants, and see how they help models deal with long-range dependencies and maintain contextual integrity. Sampling Techniques : Compare deterministic methods (e.g., greedy search, beam search) to probabilistic methods (e.g., temperature sampling, nucleus sampling) and evaluate the trade-offs involved. References: Visual intro to Transformers by 3Blue1Brown LLM Visualization by Brendan Bycroft nanoGPT by Andrej Karpathy (includes a tokenization video: here ) Attention? Attention! by Lilian Weng Decoding Strategies in LLMs by Maxime Labonne 2. Pre-training Models Pre-training LLMs is an expensive and resource-intensive process. Although this course does not primarily focus on pre-training, understanding the process, particularly regarding data handling and model parameters, is crucial. For smaller-scale hobbyist projects, pre-training on models with fewer than 1B parameters is feasible. Data Preparation : Pre-training requires vast datasets (for example, Llama 3.1 was trained on 15 trillion tokens), which must be curated, cleaned, deduplicated, and tokenized. Modern pipelines include extensive quality filtering. Distributed Training : Explore techniques such as data parallelism (distributing batches), pipeline parallelism (distributing layers), and tensor parallelism (splitting operations). These require effective network communication and memory management across GPU clusters. Training Optimization : Utilize adaptive learning rate schedules with warm-up, gradient clipping and normalization, mixed-precision training, and modern optimizers (AdamW, Lion) with well-tuned hyperparameters. Monitoring : Implement dashboards and logging to track metrics (loss, gradients, GPU usage) and profile performance to identify computational and communication bottlenecks. References: FineWeb by Penedo et al. RedPajama v2 by Weber et al. nanotron by Hugging Face (used for SmolLM2 ) Parallel Training by Chenyan Xiong Distributed Training by Duan et al. OLMo 2 by AI2 LLM360 by LLM360 3. Post-training Datasets Post-training datasets are organized with clear structures including instructions paired with answers (supervised fine-tuning) or instructions paired with chosen/rejected responses (preference alignment). Given that conversational datasets are less common compared to raw pre-training data, additional processing is often needed to enhance sample accuracy, diversity, and complexity. More details can be found in the \\ud83d\\udcbe LLM Datasets repository. Storage & Chat Templates : Due to their conversational nature, these datasets are stored in formats such as ShareGPT or OpenAI/HF. These are then mapped to chat templates like ChatML or Alpaca for training. Synthetic Data Generation : Use frontier models like GPT-4o to create instruction-response pairs from seed data. This method offers flexibility and scalability, with considerations for diverse seed tasks and effective system prompts. Data Enhancement : Enhance your samples with techniques including verified outputs (using unit tests/solvers), generating multiple answers with rejection sampling, Auto-Evol , Chain-of-Thought, Branch-Solve-Merge, persona-based approaches, and more. Quality Filtering : Traditional filtering methods involve rule-based approaches, duplicate removal (using MinHash or embeddings), and n-gram decontamination, with reward models and judge LLMs providing additional quality control. References: Synthetic Data Generator by Argilla LLM Datasets by Maxime Labonne NeMo-Curator by Nvidia Distilabel by Argilla Semhash by MinishLab Chat Template by Hugging Face 4. Supervised Fine-Tuning Supervised Fine-Tuning (SFT) transforms base models into helpful assistants capable of following instructions and structuring answers effectively. Although SFT can be used to introduce new knowledge, its ability to completely learn a new language is limited. Thus, prioritizing data quality over parameter tuning is essential. Training Techniques : Full fine-tuning updates all parameters but requires significant computational resources. Techniques like LoRA and QLoRA update only a small number of adapter parameters while keeping the base model frozen. QLoRA further combines 4-bit quantization with LoRA to minimize VRAM usage. Training Parameters : Important parameters to manage include the learning rate (with schedulers), batch size, gradient accumulation, number of epochs, optimizers (e.g., 8-bit AdamW), weight decay, warmup steps, and specific LoRA parameters (rank, alpha, target modules). Distributed Training : Utilize multiple GPUs via frameworks such as DeepSpeed or FSDP. DeepSpeed offers ZeRO optimization stages to improve memory efficiency by partitioning state information. Both frameworks support gradient checkpointing. Monitoring : Keep an eye on metrics like loss curves, learning rate changes, and gradient norms, while addressing issues such as loss spikes or gradient explosions. References: Fine-tune Llama 3.1 Ultra-Efficiently with Unsloth by Maxime Labonne Axolotl \\u2013 Documentation by Wing Lian Mastering LLMs by Hamel Husain LoRA insights by Sebastian Raschka 5. Preference Alignment Preference alignment is a secondary stage in the post-training process that helps fine-tune the model\\u2019s tone and reduce issues like toxicity and hallucinations. Its purpose is to improve performance and usefulness, and it generally involves methods like Direct Preference Optimization (DPO) and Proximal Policy Optimization (PPO). Rejection Sampling : For each prompt, generate multiple responses from the model, then score them to create on-policy data consisting of both chosen and rejected answers. Direct Preference Optimization : This method optimizes the policy by directly increasing the likelihood of chosen responses over rejected ones, without needing a separate reward model. Although it is more computationally efficient than PPO, it may offer a slight decrease in quality. Proximal Policy Optimization : This method iteratively updates the policy to maximize rewards while keeping changes close to the original behavior, using a reward model to score responses and requiring careful hyperparameter tuning (learning rate, batch size, and PPO clip range). Monitoring : Alongside SFT metrics, monitor the margin between chosen and rejected responses and track overall accuracy improvements until reaching a plateau. References: Illustrating RLHF by Hugging Face LLM Training: RLHF and Its Alternatives by Sebastian Raschka Preference Tuning LLMs by Hugging Face Fine-tune Mistral-7b with DPO by Maxime Labonne DPO Wandb logs by Alexander Vishnevskiy 6. Evaluation Evaluating LLMs reliably is a challenging but essential task for refining dataset composition and training settings. It is important to acknowledge Goodhart\\u2019s law: \\u201cWhen a measure becomes a target, it ceases to be a good measure.\\u201d Automated Benchmarks : Use curated datasets and metrics (such as MMLU) to assess performance on specific tasks. This approach works well for concrete tasks but may struggle with abstract capabilities and suffer from data contamination. Human Evaluation : Involve human assessors to prompt models and rate outputs. This method ranges from informal checks to systematic annotations and large-scale community voting (arena) and tends to work best for subjective assessments. Model-based Evaluation : Implement judge or reward models to assess generated responses. Although they often correlate well with human judgment, these models may be biased toward their own outputs. Feedback Signal : Analyze error patterns to identify shortcomings, such as problems following complex instructions, lacking specific knowledge, or being vulnerable to adversarial prompts. Use the feedback to adjust data generation and training parameters. References: Evaluation Guidebook by Cl\\u00e9mentine Fourrier Open LLM Leaderboard by Hugging Face Language Model Evaluation Harness by EleutherAI Lighteval by Hugging Face Chatbot Arena by LMSYS 7. Quantization Quantization converts a model\\u2019s parameters and activations from high precision (e.g., FP32) to lower precision (such as 4 bits) to reduce compute and memory requirements. Base Techniques : Understand the different precisions (FP32, FP16, INT8, etc.) and basic quantization methods like absmax and zero-point techniques. GGUF & llama.cpp : Originally created for CPU-based runs, llama.cpp and the GGUF format are now widely used to run LLMs on consumer hardware. They support the storage of special tokens, vocabulary, and metadata all in one file. GPTQ & AWQ : Methods such as GPTQ / EXL2 and AWQ use layer-wise calibration to maintain performance at very low bitwidths. These techniques adjust scaling dynamically and can selectively bypass or re-center the heaviest parameters. SmoothQuant & ZeroQuant : New methods such as SmoothQuant (which applies quantization-friendly transformations) and compiler-based optimizations like ZeroQuant help alleviate outlier issues before quantization, optimizing data flow and reducing hardware overhead. References: Introduction to Quantization by Maxime Labonne Quantize Llama models with llama.cpp by Maxime Labonne 4-bit LLM Quantization with GPTQ by Maxime Labonne Understanding Activation-Aware Weight Quantization by FriendliAI SmoothQuant on Llama 2 7B by MIT HAN Lab DeepSpeed Model Compression by DeepSpeed 8. New Trends This section covers emerging topics that do not neatly fit into other categories. Some ideas, like model merging and multimodal models, are well established, while others\\u2014such as interpretability or test-time compute scaling\\u2014are more experimental and actively researched. Model Merging : Merging pre-trained models has become a popular technique for boosting performance without additional fine-tuning. The mergekit library implements several popular merging methods, including SLERP, DARE , and TIES . Multimodal Models : Models like CLIP , Stable Diffusion , and LLaVA are designed to process and integrate various types of inputs (text, images, audio, etc.) within a unified embedding space, enabling powerful applications such as text-to-image generation. Interpretability : Mechanistic interpretability approaches, including Sparse Autoencoders (SAEs) and techniques like abliteration, offer insights into the internal operations of LLMs and can allow for behavioral adjustments without retraining. Test-time Compute : Scaling computational resources during inference often requires multiple calls and specialized models (e.g., Process Reward Model (PRM)). Iterative procedures with fine-tuned scoring can markedly enhance performance on complex reasoning tasks. References: Merge LLMs with mergekit by Maxime Labonne Smol Vision by Merve Noyan Large Multimodal Models by Chip Huyen Uncensor any LLM with abliteration by Maxime Labonne Intuitive Explanation of SAEs by Adam Karvonen Scaling test-time compute by Beeching et al. The LLM Engineer This part of the course teaches you how to build production-grade applications powered by LLMs, with a focus on augmenting models and deploying them. 1. Running LLMs Running LLMs can be challenging given their high hardware requirements. Depending on your needs, you might opt to use an API (like GPT-4) or run a model locally. In either case, careful prompting and guidance can greatly enhance output quality and relevance. LLM APIs : APIs provide a convenient way to access LLMs. They are divided between private LLMs (e.g., OpenAI , Google , Anthropic , Cohere ) and open-source LLMs (e.g., OpenRouter , Hugging Face , Together AI ). Open-source LLMs : The Hugging Face Hub is a prime resource for finding LLMs. You can run many of these models in Hugging Face Spaces , or download and operate them locally using tools like LM Studio , llama.cpp , or Ollama . Prompt Engineering : Techniques such as zero-shot prompting, few-shot prompting, chain-of-thought, and ReAct are common. While these methods work better with larger models, they can be adapted for smaller ones. Structuring Outputs : Some tasks require outputs to follow a strict format (such as a JSON format or specific template). Tools such as LMQL , Outlines , and Guidance help ensure the generated text adheres to the required structure. References: Run an LLM locally with LM Studio by Nisha Arya Prompt engineering guide by DAIR.AI Outlines \\u2013 Quickstart LMQL \\u2013 Overview 2. Building a Vector Storage The first step in creating a Retrieval Augmented Generation (RAG) pipeline is establishing a vector storage. This involves loading documents, splitting them into manageable pieces, and then converting key text chunks into vector embeddings for future retrieval. Ingesting Documents : Document loaders can process multiple formats such as PDF, JSON, HTML, and Markdown. They can also pull in data directly from databases and APIs (e.g., GitHub, Reddit, Google Drive). Splitting Documents : Text splitters divide documents into smaller, semantically relevant chunks. Instead of a fixed character count, splitting by headers or recursively\\u2014while preserving metadata\\u2014often yields better results. Embedding Models : These models transform text into vector representations, enabling a more nuanced semantic interpretation that is essential for effective search. Vector Databases : Databases like Chroma , Pinecone , Milvus , FAISS , and Annoy are designed for storing embeddings, allowing for fast similarity-based retrieval. References: LangChain \\u2013 Text splitters Sentence Transformers library MTEB Leaderboard The Top 5 Vector Databases by Moez Ali 3. Retrieval Augmented Generation Retrieval Augmented Generation (RAG) enhances LLM outputs by using relevant contextual documents fetched from a vector database, thus improving answer accuracy without needing additional fine-tuning. Orchestrators : Tools like LangChain , LlamaIndex , and FastRAG connect LLMs to tools, databases, and memory systems, extending their functionality. Retrievers : Since user queries may not be optimized for search, techniques such as multi-query retrievers or HyDE can reformulate queries to improve retrieval performance. Memory : To maintain context over a conversation, LLMs use a history buffer that can be enhanced with summarization techniques or integrated with vector stores via RAG. Evaluation : It is crucial to assess both the document retrieval process (precision and recall) and the generation stage (faithfulness and relevancy). Tools like Ragas and DeepEval can assist in these evaluations. References: Llamaindex \\u2013 High-level concepts Pinecone \\u2013 Retrieval Augmentation LangChain \\u2013 Q&A with RAG LangChain \\u2013 Memory types RAG pipeline \\u2013 Metrics 4. Advanced RAG In real-world scenarios, you may need to develop more complex pipelines involving SQL or graph databases, as well as systems that automatically select appropriate tools and APIs to enhance the baseline RAG setup. Query Construction : For structured data stored in databases, you need to translate user instructions into appropriate query languages like SQL or Cypher. Agents and Tools : LLM agents can automatically choose the most suitable tools\\u2014ranging from simple web searches (e.g., Google, Wikipedia) to complex systems (e.g., Python interpreters, Jira)\\u2014to answer queries. Post-Processing : Enhance the overall relevance of retrieved documents using re-ranking methods, RAG-fusion , or classification techniques. Program LLMs : Frameworks like DSPy allow you to fine-tune prompts and model parameters programmatically based on automated evaluations. References: LangChain \\u2013 Query Construction LangChain \\u2013 SQL Pinecone \\u2013 LLM agents LLM Powered Autonomous Agents by Lilian Weng LangChain \\u2013 OpenAI\\u2019s RAG DSPy in 8 Steps 5. Inference Optimization Since generating text is computationally intensive, several techniques exist to maximize throughput and reduce inference costs alongside quantization. Flash Attention : Optimizes the attention mechanism by reducing its complexity from quadratic to linear, thereby speeding up both training and inference. Key-value Cache : Learn about the key-value cache and enhancements like Multi-Query Attention (MQA) and Grouped-Query Attention (GQA). Speculative Decoding : Use a smaller model to produce draft outputs that are later refined by a larger model, thus accelerating text generation. References: GPU Inference by Hugging Face LLM Inference by Databricks Optimizing LLMs for Speed and Memory by Hugging Face Assisted Generation by Hugging Face 6. Deploying LLMs Deploying LLMs, especially at scale, is complex and may require multiple GPU clusters. However, demos or local applications often have simpler requirements. Local Deployment : Open-source LLMs offer privacy advantages over private models. Solutions such as LM Studio , Ollama , oobabooga , and kobold.cpp facilitate local deployment. Demo Deployment : Tools like Gradio and Streamlit are excellent for prototyping apps and sharing demos. They are also easy to host online (for example, on Hugging Face Spaces ). Server Deployment : Running LLMs at scale often demands cloud infrastructure (or on-prem solutions) and specialized frameworks such as TGI or vLLM . Edge Deployment : In resource-constrained environments, frameworks like MLC LLM and mnn-llm enable deployment on web browsers, Android, and iOS. References: Streamlit \\u2013 Build a basic LLM app by Streamlit HF LLM Inference Container by Hugging Face Philschmid blog by Philipp Schmid Optimizing Latency by Hamel Husain 7. Securing LLMs LLM applications bring their own unique security challenges in addition to standard software vulnerabilities. Prompt Hacking : This includes issues like prompt injection (where unwanted instructions hijack the model), data/prompt leaking (extracting the original prompt or training data), and jailbreaking (bypassing the model\\u2019s safety features). Backdoors : These attacks can target training data by poisoning it with false or malicious content, or by introducing hidden triggers that alter model behavior during inference. Defensive Measures : Protect your LLM applications by testing them for vulnerabilities using techniques such as red teaming and tools like garak , while monitoring in production with frameworks like langfuse . References: OWASP LLM Top 10 by HEGO Wiki Prompt Injection Primer by Joseph Thacker LLM Security by @llm_sec Red teaming LLMs by Microsoft \\u2190 Previous Next \\u2192\", \"score\": 5, \"type\": \"image\", \"group_id\": 1, \"format\": \"jpg\", \"width\": 768}, {\"src\": \"https://originshq.com/wp-content/uploads/2025/01/top_learning_resource_ai_llm_in_2025-1536x864.jpg\", \"alt\": \"Top AI/LLM learning resource in 2025\", \"desc\": \"Table of Contents \\ud83d\\udcdd Notebooks Tools Fine-tuning Quantization Other LLM Fundamentals 1. Mathematics for Machine Learning 2. Python for Machine Learning 3. Neural Networks 4. Natural Language Processing (NLP) The LLM Scientist 1. The LLM Architecture 2. Pre-training Models 3. Post-training Datasets 4. Supervised Fine-Tuning 5. Preference Alignment 6. Evaluation 7. Quantization 8. New Trends The LLM Engineer 1. Running LLMs 2. Building a Vector Storage 3. Retrieval Augmented Generation 4. Advanced RAG 5. Inference Optimization 6. Deploying LLMs 7. Securing LLMs Seeking Experts for Implementing AI ? The Blog is organized into three main segments: LLM Fundamentals (optional) \\u2013 Covers essential topics such as mathematics, Python, and neural networks. The LLM Scientist \\u2013 Concentrates on creating the best-performing LLMs using state-of-the-art techniques. The LLM Engineer \\u2013 Focuses on building applications based on LLMs and deploying them. \\ud83d\\udcdd Notebooks Below is a collection of notebooks and articles dedicated to LLMs. Tools Notebook Name Description Notebook \\ud83e\\uddd0 LLM AutoEval Evaluate your LLMs automatically using RunPod. Notebook \\ud83e\\udd71 LazyMergekit Merge models effortlessly using MergeKit with a single click. Notebook \\ud83e\\udd8e LazyAxolotl Fine-tune models in the cloud with Axolotl in just one click. Notebook \\u26a1 AutoQuant Quantize LLMs into GGUF, GPTQ, EXL2, AWQ, and HQQ formats in one click. Notebook \\ud83c\\udf33 Model Family Tree Visualize the lineage of merged models. Notebook \\ud83d\\ude80 ZeroSpace Instantly create a Gradio chat interface using a free ZeroGPU. Notebook Fine-tuning Notebook Name Description Article Notebook Fine-tune Llama 3.1 with Unsloth Perform ultra-efficient supervised fine-tuning in Google Colab. Article Notebook Fine-tune Llama 3 with ORPO Achieve cheaper and faster fine-tuning in a single stage with ORPO. Article Notebook Fine-tune Mistral-7b with DPO Enhance the performance of supervised fine-tuned models using DPO. Article Notebook Fine-tune Mistral-7b with QLoRA Supervised fine-tuning of Mistral-7b in a free-tier Google Colab using TRL. Notebook Fine-tune CodeLlama using Axolotl A comprehensive guide to fine-tune with the state-of-the-art Axolotl tool. Article Notebook Fine-tune Llama 2 with QLoRA A step-by-step guide to supervised fine-tuning of Llama 2 in Google Colab. Article Notebook Quantization Notebook Name Description Article Notebook Introduction to Quantization An overview of optimizing large language models using 8-bit quantization. Article Notebook 4-bit Quantization using GPTQ Learn to quantize your open-source LLMs for consumer hardware using GPTQ. Article Notebook Quantization with GGUF and llama.cpp Quantize Llama 2 models with llama.cpp and upload their GGUF versions to the HF Hub. Article Notebook ExLlamaV2: The Fastest Library to Run LLMs Quantize and run EXL2 models, then upload them to the HF Hub. Article Notebook Other Notebook Name Description Article Notebook Merge LLMs with MergeKit Easily create your own models without needing a GPU. Article Notebook Create MoEs with MergeKit Combine multiple experts into a single frankenMoE. Article Notebook Uncensor any LLM with abliteration Fine-tuning strategies without retraining the model. Article Notebook Improve ChatGPT with Knowledge Graphs Augment ChatGPT\\u2019s responses using knowledge graphs. Article Notebook Decoding Strategies in Large Language Models A comprehensive guide covering text generation methods from beam search to nucleus sampling. Article Notebook LLM Fundamentals This section provides core knowledge about mathematics, Python, and neural networks. While you may not begin here if you already have the basics, feel free to refer back as needed. 1. Mathematics for Machine Learning Before diving deep into machine learning, it is essential to master the fundamental mathematical concepts that underpin these algorithms: Linear Algebra : Crucial for many algorithms, particularly in deep learning. Topics include vectors, matrices, determinants, eigenvalues and eigenvectors, vector spaces, and linear transformations. Calculus : Needed to optimize continuous functions. Learn about derivatives, integrals, limits, series, multivariable calculus, and gradient concepts. Probability and Statistics : Key for understanding model behavior and data prediction. Essential topics include probability theory, random variables, distributions, expectations, variance, covariance, correlation, hypothesis testing, confidence intervals, maximum likelihood estimation, and Bayesian inference. Resources: 3Blue1Brown \\u2013 The Essence of Linear Algebra StatQuest with Josh Starmer \\u2013 Statistics Fundamentals AP Statistics Intuition by Ms Aerin Immersive Linear Algebra Khan Academy \\u2013 Linear Algebra Khan Academy \\u2013 Calculus Khan Academy \\u2013 Probability and Statistics 2. Python for Machine Learning Python is a flexible and powerful language, especially suited for machine learning because of its clear syntax and extensive ecosystem. Python Basics : Understand basic syntax, data types, error handling, and object-oriented programming. Data Science Libraries : Gain experience with NumPy for numerical operations; Pandas for data manipulation; and Matplotlib/Seaborn for visualizations. Data Preprocessing : Learn techniques such as feature scaling, normalization, handling missing values, outlier detection, encoding categorical data, and data splitting. Machine Learning Libraries : Familiarize yourself with Scikit-learn, which offers numerous supervised and unsupervised algorithms. Understand implementations of linear regression, logistic regression, decision trees, random forests, k-nearest neighbors, K-means clustering, and dimensionality reduction methods like PCA and t-SNE. Resources: Real Python freeCodeCamp \\u2013 Learn Python Python Data Science Handbook freeCodeCamp \\u2013 Machine Learning for Everybody Udacity \\u2013 Intro to Machine Learning 3. Neural Networks Neural networks form the backbone of many modern deep learning models. It\\u2019s important to understand how they work and are built: Fundamentals : Know the basic structure including layers, weights, biases, and activation functions (sigmoid, tanh, ReLU, etc.). Training and Optimization : Get to know backpropagation, common loss functions (MSE, Cross-Entropy), and optimization algorithms (Gradient Descent, SGD, RMSprop, Adam). Overfitting : Understand what overfitting means and study regularization techniques such as dropout, L1/L2 regularization, early stopping, and data augmentation. Implementing a Multilayer Perceptron (MLP) : Build an MLP (a fully connected network) using frameworks like PyTorch. Resources: 3Blue1Brown \\u2013 But what is a Neural Network? freeCodeCamp \\u2013 Deep Learning Crash Course Fast.ai \\u2013 Practical Deep Learning Patrick Loeber \\u2013 PyTorch Tutorials 4. Natural Language Processing (NLP) NLP is an exciting field that connects human language with machine comprehension. It ranges from basic text processing to capturing intricate linguistic nuances. Text Preprocessing : Understand tokenization (dividing text into words or sentences), stemming (reducing words to their roots), lemmatization (context-aware reduction), and stop word removal. Feature Extraction Techniques : Learn how to transform textual data for machine learning algorithms using techniques like Bag-of-Words (BoW), TF-IDF, and n-grams. Word Embeddings : Study methods such as Word2Vec, GloVe, and FastText which allow words with similar meanings to have similar vector representations. Recurrent Neural Networks (RNNs) : Learn how RNNs are designed for sequential data and explore variants like LSTMs and GRUs, which capture long-term dependencies. Resources: Lena Voita \\u2013 Word Embeddings RealPython \\u2013 NLP with spaCy in Python Kaggle \\u2013 NLP Guide Jay Alammar \\u2013 The Illustration Word2Vec Jake Tae \\u2013 PyTorch RNN from Scratch colah\\u2019s blog \\u2013 Understanding LSTM Networks The LLM Scientist This section is designed to help you learn how to build the most effective LLMs using the latest methodologies. 1. The LLM Architecture You don\\u2019t need an exhaustive understanding of the Transformer architecture, but it is important to know the major steps in modern LLMs: converting text into numeric tokens, processing these tokens with layers (including attention mechanisms), and using various sampling strategies to generate text. Architectural Overview : Trace the evolution from encoder-decoder Transformers to decoder-only structures like GPT, which are fundamental to modern LLMs. Understand how these models process and generate text at a high level. Tokenization : Learn the principles behind tokenization and how it transforms text into numerical data that models can process. Investigate different tokenization strategies and their effects on performance and output quality. Attention Mechanisms : Master the concept of attention, particularly self-attention and its variants, and see how they help models deal with long-range dependencies and maintain contextual integrity. Sampling Techniques : Compare deterministic methods (e.g., greedy search, beam search) to probabilistic methods (e.g., temperature sampling, nucleus sampling) and evaluate the trade-offs involved. References: Visual intro to Transformers by 3Blue1Brown LLM Visualization by Brendan Bycroft nanoGPT by Andrej Karpathy (includes a tokenization video: here ) Attention? Attention! by Lilian Weng Decoding Strategies in LLMs by Maxime Labonne 2. Pre-training Models Pre-training LLMs is an expensive and resource-intensive process. Although this course does not primarily focus on pre-training, understanding the process, particularly regarding data handling and model parameters, is crucial. For smaller-scale hobbyist projects, pre-training on models with fewer than 1B parameters is feasible. Data Preparation : Pre-training requires vast datasets (for example, Llama 3.1 was trained on 15 trillion tokens), which must be curated, cleaned, deduplicated, and tokenized. Modern pipelines include extensive quality filtering. Distributed Training : Explore techniques such as data parallelism (distributing batches), pipeline parallelism (distributing layers), and tensor parallelism (splitting operations). These require effective network communication and memory management across GPU clusters. Training Optimization : Utilize adaptive learning rate schedules with warm-up, gradient clipping and normalization, mixed-precision training, and modern optimizers (AdamW, Lion) with well-tuned hyperparameters. Monitoring : Implement dashboards and logging to track metrics (loss, gradients, GPU usage) and profile performance to identify computational and communication bottlenecks. References: FineWeb by Penedo et al. RedPajama v2 by Weber et al. nanotron by Hugging Face (used for SmolLM2 ) Parallel Training by Chenyan Xiong Distributed Training by Duan et al. OLMo 2 by AI2 LLM360 by LLM360 3. Post-training Datasets Post-training datasets are organized with clear structures including instructions paired with answers (supervised fine-tuning) or instructions paired with chosen/rejected responses (preference alignment). Given that conversational datasets are less common compared to raw pre-training data, additional processing is often needed to enhance sample accuracy, diversity, and complexity. More details can be found in the \\ud83d\\udcbe LLM Datasets repository. Storage & Chat Templates : Due to their conversational nature, these datasets are stored in formats such as ShareGPT or OpenAI/HF. These are then mapped to chat templates like ChatML or Alpaca for training. Synthetic Data Generation : Use frontier models like GPT-4o to create instruction-response pairs from seed data. This method offers flexibility and scalability, with considerations for diverse seed tasks and effective system prompts. Data Enhancement : Enhance your samples with techniques including verified outputs (using unit tests/solvers), generating multiple answers with rejection sampling, Auto-Evol , Chain-of-Thought, Branch-Solve-Merge, persona-based approaches, and more. Quality Filtering : Traditional filtering methods involve rule-based approaches, duplicate removal (using MinHash or embeddings), and n-gram decontamination, with reward models and judge LLMs providing additional quality control. References: Synthetic Data Generator by Argilla LLM Datasets by Maxime Labonne NeMo-Curator by Nvidia Distilabel by Argilla Semhash by MinishLab Chat Template by Hugging Face 4. Supervised Fine-Tuning Supervised Fine-Tuning (SFT) transforms base models into helpful assistants capable of following instructions and structuring answers effectively. Although SFT can be used to introduce new knowledge, its ability to completely learn a new language is limited. Thus, prioritizing data quality over parameter tuning is essential. Training Techniques : Full fine-tuning updates all parameters but requires significant computational resources. Techniques like LoRA and QLoRA update only a small number of adapter parameters while keeping the base model frozen. QLoRA further combines 4-bit quantization with LoRA to minimize VRAM usage. Training Parameters : Important parameters to manage include the learning rate (with schedulers), batch size, gradient accumulation, number of epochs, optimizers (e.g., 8-bit AdamW), weight decay, warmup steps, and specific LoRA parameters (rank, alpha, target modules). Distributed Training : Utilize multiple GPUs via frameworks such as DeepSpeed or FSDP. DeepSpeed offers ZeRO optimization stages to improve memory efficiency by partitioning state information. Both frameworks support gradient checkpointing. Monitoring : Keep an eye on metrics like loss curves, learning rate changes, and gradient norms, while addressing issues such as loss spikes or gradient explosions. References: Fine-tune Llama 3.1 Ultra-Efficiently with Unsloth by Maxime Labonne Axolotl \\u2013 Documentation by Wing Lian Mastering LLMs by Hamel Husain LoRA insights by Sebastian Raschka 5. Preference Alignment Preference alignment is a secondary stage in the post-training process that helps fine-tune the model\\u2019s tone and reduce issues like toxicity and hallucinations. Its purpose is to improve performance and usefulness, and it generally involves methods like Direct Preference Optimization (DPO) and Proximal Policy Optimization (PPO). Rejection Sampling : For each prompt, generate multiple responses from the model, then score them to create on-policy data consisting of both chosen and rejected answers. Direct Preference Optimization : This method optimizes the policy by directly increasing the likelihood of chosen responses over rejected ones, without needing a separate reward model. Although it is more computationally efficient than PPO, it may offer a slight decrease in quality. Proximal Policy Optimization : This method iteratively updates the policy to maximize rewards while keeping changes close to the original behavior, using a reward model to score responses and requiring careful hyperparameter tuning (learning rate, batch size, and PPO clip range). Monitoring : Alongside SFT metrics, monitor the margin between chosen and rejected responses and track overall accuracy improvements until reaching a plateau. References: Illustrating RLHF by Hugging Face LLM Training: RLHF and Its Alternatives by Sebastian Raschka Preference Tuning LLMs by Hugging Face Fine-tune Mistral-7b with DPO by Maxime Labonne DPO Wandb logs by Alexander Vishnevskiy 6. Evaluation Evaluating LLMs reliably is a challenging but essential task for refining dataset composition and training settings. It is important to acknowledge Goodhart\\u2019s law: \\u201cWhen a measure becomes a target, it ceases to be a good measure.\\u201d Automated Benchmarks : Use curated datasets and metrics (such as MMLU) to assess performance on specific tasks. This approach works well for concrete tasks but may struggle with abstract capabilities and suffer from data contamination. Human Evaluation : Involve human assessors to prompt models and rate outputs. This method ranges from informal checks to systematic annotations and large-scale community voting (arena) and tends to work best for subjective assessments. Model-based Evaluation : Implement judge or reward models to assess generated responses. Although they often correlate well with human judgment, these models may be biased toward their own outputs. Feedback Signal : Analyze error patterns to identify shortcomings, such as problems following complex instructions, lacking specific knowledge, or being vulnerable to adversarial prompts. Use the feedback to adjust data generation and training parameters. References: Evaluation Guidebook by Cl\\u00e9mentine Fourrier Open LLM Leaderboard by Hugging Face Language Model Evaluation Harness by EleutherAI Lighteval by Hugging Face Chatbot Arena by LMSYS 7. Quantization Quantization converts a model\\u2019s parameters and activations from high precision (e.g., FP32) to lower precision (such as 4 bits) to reduce compute and memory requirements. Base Techniques : Understand the different precisions (FP32, FP16, INT8, etc.) and basic quantization methods like absmax and zero-point techniques. GGUF & llama.cpp : Originally created for CPU-based runs, llama.cpp and the GGUF format are now widely used to run LLMs on consumer hardware. They support the storage of special tokens, vocabulary, and metadata all in one file. GPTQ & AWQ : Methods such as GPTQ / EXL2 and AWQ use layer-wise calibration to maintain performance at very low bitwidths. These techniques adjust scaling dynamically and can selectively bypass or re-center the heaviest parameters. SmoothQuant & ZeroQuant : New methods such as SmoothQuant (which applies quantization-friendly transformations) and compiler-based optimizations like ZeroQuant help alleviate outlier issues before quantization, optimizing data flow and reducing hardware overhead. References: Introduction to Quantization by Maxime Labonne Quantize Llama models with llama.cpp by Maxime Labonne 4-bit LLM Quantization with GPTQ by Maxime Labonne Understanding Activation-Aware Weight Quantization by FriendliAI SmoothQuant on Llama 2 7B by MIT HAN Lab DeepSpeed Model Compression by DeepSpeed 8. New Trends This section covers emerging topics that do not neatly fit into other categories. Some ideas, like model merging and multimodal models, are well established, while others\\u2014such as interpretability or test-time compute scaling\\u2014are more experimental and actively researched. Model Merging : Merging pre-trained models has become a popular technique for boosting performance without additional fine-tuning. The mergekit library implements several popular merging methods, including SLERP, DARE , and TIES . Multimodal Models : Models like CLIP , Stable Diffusion , and LLaVA are designed to process and integrate various types of inputs (text, images, audio, etc.) within a unified embedding space, enabling powerful applications such as text-to-image generation. Interpretability : Mechanistic interpretability approaches, including Sparse Autoencoders (SAEs) and techniques like abliteration, offer insights into the internal operations of LLMs and can allow for behavioral adjustments without retraining. Test-time Compute : Scaling computational resources during inference often requires multiple calls and specialized models (e.g., Process Reward Model (PRM)). Iterative procedures with fine-tuned scoring can markedly enhance performance on complex reasoning tasks. References: Merge LLMs with mergekit by Maxime Labonne Smol Vision by Merve Noyan Large Multimodal Models by Chip Huyen Uncensor any LLM with abliteration by Maxime Labonne Intuitive Explanation of SAEs by Adam Karvonen Scaling test-time compute by Beeching et al. The LLM Engineer This part of the course teaches you how to build production-grade applications powered by LLMs, with a focus on augmenting models and deploying them. 1. Running LLMs Running LLMs can be challenging given their high hardware requirements. Depending on your needs, you might opt to use an API (like GPT-4) or run a model locally. In either case, careful prompting and guidance can greatly enhance output quality and relevance. LLM APIs : APIs provide a convenient way to access LLMs. They are divided between private LLMs (e.g., OpenAI , Google , Anthropic , Cohere ) and open-source LLMs (e.g., OpenRouter , Hugging Face , Together AI ). Open-source LLMs : The Hugging Face Hub is a prime resource for finding LLMs. You can run many of these models in Hugging Face Spaces , or download and operate them locally using tools like LM Studio , llama.cpp , or Ollama . Prompt Engineering : Techniques such as zero-shot prompting, few-shot prompting, chain-of-thought, and ReAct are common. While these methods work better with larger models, they can be adapted for smaller ones. Structuring Outputs : Some tasks require outputs to follow a strict format (such as a JSON format or specific template). Tools such as LMQL , Outlines , and Guidance help ensure the generated text adheres to the required structure. References: Run an LLM locally with LM Studio by Nisha Arya Prompt engineering guide by DAIR.AI Outlines \\u2013 Quickstart LMQL \\u2013 Overview 2. Building a Vector Storage The first step in creating a Retrieval Augmented Generation (RAG) pipeline is establishing a vector storage. This involves loading documents, splitting them into manageable pieces, and then converting key text chunks into vector embeddings for future retrieval. Ingesting Documents : Document loaders can process multiple formats such as PDF, JSON, HTML, and Markdown. They can also pull in data directly from databases and APIs (e.g., GitHub, Reddit, Google Drive). Splitting Documents : Text splitters divide documents into smaller, semantically relevant chunks. Instead of a fixed character count, splitting by headers or recursively\\u2014while preserving metadata\\u2014often yields better results. Embedding Models : These models transform text into vector representations, enabling a more nuanced semantic interpretation that is essential for effective search. Vector Databases : Databases like Chroma , Pinecone , Milvus , FAISS , and Annoy are designed for storing embeddings, allowing for fast similarity-based retrieval. References: LangChain \\u2013 Text splitters Sentence Transformers library MTEB Leaderboard The Top 5 Vector Databases by Moez Ali 3. Retrieval Augmented Generation Retrieval Augmented Generation (RAG) enhances LLM outputs by using relevant contextual documents fetched from a vector database, thus improving answer accuracy without needing additional fine-tuning. Orchestrators : Tools like LangChain , LlamaIndex , and FastRAG connect LLMs to tools, databases, and memory systems, extending their functionality. Retrievers : Since user queries may not be optimized for search, techniques such as multi-query retrievers or HyDE can reformulate queries to improve retrieval performance. Memory : To maintain context over a conversation, LLMs use a history buffer that can be enhanced with summarization techniques or integrated with vector stores via RAG. Evaluation : It is crucial to assess both the document retrieval process (precision and recall) and the generation stage (faithfulness and relevancy). Tools like Ragas and DeepEval can assist in these evaluations. References: Llamaindex \\u2013 High-level concepts Pinecone \\u2013 Retrieval Augmentation LangChain \\u2013 Q&A with RAG LangChain \\u2013 Memory types RAG pipeline \\u2013 Metrics 4. Advanced RAG In real-world scenarios, you may need to develop more complex pipelines involving SQL or graph databases, as well as systems that automatically select appropriate tools and APIs to enhance the baseline RAG setup. Query Construction : For structured data stored in databases, you need to translate user instructions into appropriate query languages like SQL or Cypher. Agents and Tools : LLM agents can automatically choose the most suitable tools\\u2014ranging from simple web searches (e.g., Google, Wikipedia) to complex systems (e.g., Python interpreters, Jira)\\u2014to answer queries. Post-Processing : Enhance the overall relevance of retrieved documents using re-ranking methods, RAG-fusion , or classification techniques. Program LLMs : Frameworks like DSPy allow you to fine-tune prompts and model parameters programmatically based on automated evaluations. References: LangChain \\u2013 Query Construction LangChain \\u2013 SQL Pinecone \\u2013 LLM agents LLM Powered Autonomous Agents by Lilian Weng LangChain \\u2013 OpenAI\\u2019s RAG DSPy in 8 Steps 5. Inference Optimization Since generating text is computationally intensive, several techniques exist to maximize throughput and reduce inference costs alongside quantization. Flash Attention : Optimizes the attention mechanism by reducing its complexity from quadratic to linear, thereby speeding up both training and inference. Key-value Cache : Learn about the key-value cache and enhancements like Multi-Query Attention (MQA) and Grouped-Query Attention (GQA). Speculative Decoding : Use a smaller model to produce draft outputs that are later refined by a larger model, thus accelerating text generation. References: GPU Inference by Hugging Face LLM Inference by Databricks Optimizing LLMs for Speed and Memory by Hugging Face Assisted Generation by Hugging Face 6. Deploying LLMs Deploying LLMs, especially at scale, is complex and may require multiple GPU clusters. However, demos or local applications often have simpler requirements. Local Deployment : Open-source LLMs offer privacy advantages over private models. Solutions such as LM Studio , Ollama , oobabooga , and kobold.cpp facilitate local deployment. Demo Deployment : Tools like Gradio and Streamlit are excellent for prototyping apps and sharing demos. They are also easy to host online (for example, on Hugging Face Spaces ). Server Deployment : Running LLMs at scale often demands cloud infrastructure (or on-prem solutions) and specialized frameworks such as TGI or vLLM . Edge Deployment : In resource-constrained environments, frameworks like MLC LLM and mnn-llm enable deployment on web browsers, Android, and iOS. References: Streamlit \\u2013 Build a basic LLM app by Streamlit HF LLM Inference Container by Hugging Face Philschmid blog by Philipp Schmid Optimizing Latency by Hamel Husain 7. Securing LLMs LLM applications bring their own unique security challenges in addition to standard software vulnerabilities. Prompt Hacking : This includes issues like prompt injection (where unwanted instructions hijack the model), data/prompt leaking (extracting the original prompt or training data), and jailbreaking (bypassing the model\\u2019s safety features). Backdoors : These attacks can target training data by poisoning it with false or malicious content, or by introducing hidden triggers that alter model behavior during inference. Defensive Measures : Protect your LLM applications by testing them for vulnerabilities using techniques such as red teaming and tools like garak , while monitoring in production with frameworks like langfuse . References: OWASP LLM Top 10 by HEGO Wiki Prompt Injection Primer by Joseph Thacker LLM Security by @llm_sec Red teaming LLMs by Microsoft \\u2190 Previous Next \\u2192\", \"score\": 5, \"type\": \"image\", \"group_id\": 1, \"format\": \"jpg\", \"width\": 1536}], \"videos\": [], \"audios\": []}",
    "links": "{\"internal\": [{\"href\": \"https://originshq.com/\", \"text\": \"\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/top-ai-llm-learning-resource-in-2025/\", \"text\": \"Home\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog\", \"text\": \"Blog\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/services-devops/\", \"text\": \"Devops\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/services-cloud/\", \"text\": \"Cloud\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/services-data/\", \"text\": \"Data\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/services-mobileapp/\", \"text\": \"App Development\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/services-ai/\", \"text\": \"AI Services\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/services-tech-consulting/\", \"text\": \"Tech Consulting\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/our-works/building-an-ai-testing-platform/\", \"text\": \"Raga AI \\u2013 AI Platform\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/our-works/samsung-iot-development-and-user-verification/\", \"text\": \"Samsung \\u2013 IOT\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/our-works/cost-reduction-at-amazon/\", \"text\": \"Amazon \\u2013 Cost Reduction\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/our-works/building-platform-at-nucash/\", \"text\": \"Nucash \\u2013 Building Platform\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/our-works/helping-frontpage-scale/\", \"text\": \"FrontPage \\u2013 Scalability Issues\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/our-works/transforming-yesmadam-into-a-tech-company/\", \"text\": \"YesMadam \\u2013 Digital Transformation\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/book-a-call/\", \"text\": \"Contact Us\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/top-ai-llm-learning-resource-in-2025/#ib-toc-anchor-0\", \"text\": \"\\ud83d\\udcdd Notebooks\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/top-ai-llm-learning-resource-in-2025/#ib-toc-anchor-1\", \"text\": \"Tools\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/top-ai-llm-learning-resource-in-2025/#ib-toc-anchor-2\", \"text\": \"Fine-tuning\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/top-ai-llm-learning-resource-in-2025/#ib-toc-anchor-3\", \"text\": \"Quantization\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/top-ai-llm-learning-resource-in-2025/#ib-toc-anchor-4\", \"text\": \"Other\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/top-ai-llm-learning-resource-in-2025/#ib-toc-anchor-5\", \"text\": \"LLM Fundamentals\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/top-ai-llm-learning-resource-in-2025/#ib-toc-anchor-6\", \"text\": \"1. Mathematics for Machine Learning\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/top-ai-llm-learning-resource-in-2025/#ib-toc-anchor-7\", \"text\": \"2. Python for Machine Learning\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/top-ai-llm-learning-resource-in-2025/#ib-toc-anchor-8\", \"text\": \"3. Neural Networks\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/top-ai-llm-learning-resource-in-2025/#ib-toc-anchor-9\", \"text\": \"4. Natural Language Processing (NLP)\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/top-ai-llm-learning-resource-in-2025/#ib-toc-anchor-10\", \"text\": \"The LLM Scientist\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/top-ai-llm-learning-resource-in-2025/#ib-toc-anchor-11\", \"text\": \"1. The LLM Architecture\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/top-ai-llm-learning-resource-in-2025/#ib-toc-anchor-12\", \"text\": \"2. Pre-training Models\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/top-ai-llm-learning-resource-in-2025/#ib-toc-anchor-13\", \"text\": \"3. Post-training Datasets\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/top-ai-llm-learning-resource-in-2025/#ib-toc-anchor-14\", \"text\": \"4. Supervised Fine-Tuning\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/top-ai-llm-learning-resource-in-2025/#ib-toc-anchor-15\", \"text\": \"5. Preference Alignment\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/top-ai-llm-learning-resource-in-2025/#ib-toc-anchor-16\", \"text\": \"6. Evaluation\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/top-ai-llm-learning-resource-in-2025/#ib-toc-anchor-17\", \"text\": \"7. Quantization\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/top-ai-llm-learning-resource-in-2025/#ib-toc-anchor-18\", \"text\": \"8. New Trends\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/top-ai-llm-learning-resource-in-2025/#ib-toc-anchor-19\", \"text\": \"The LLM Engineer\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/top-ai-llm-learning-resource-in-2025/#ib-toc-anchor-20\", \"text\": \"1. Running LLMs\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/top-ai-llm-learning-resource-in-2025/#ib-toc-anchor-21\", \"text\": \"2. Building a Vector Storage\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/top-ai-llm-learning-resource-in-2025/#ib-toc-anchor-22\", \"text\": \"3. Retrieval Augmented Generation\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/top-ai-llm-learning-resource-in-2025/#ib-toc-anchor-23\", \"text\": \"4. Advanced RAG\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/top-ai-llm-learning-resource-in-2025/#ib-toc-anchor-24\", \"text\": \"5. Inference Optimization\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/top-ai-llm-learning-resource-in-2025/#ib-toc-anchor-25\", \"text\": \"6. Deploying LLMs\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/top-ai-llm-learning-resource-in-2025/#ib-toc-anchor-26\", \"text\": \"7. Securing LLMs\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/top-ai-llm-learning-resource-in-2025/#ib-toc-anchor-27\", \"text\": \"Seeking Experts for Implementing AI ?\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/fine-tune-llama-3-1-ultra-efficiently-with-unsloth/\", \"text\": \"Article\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/fine-tune-llama-3-with-orpo/\", \"text\": \"Article\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/boost-the-performance-of-supervised-fine-tuned-models-with-dpo/\", \"text\": \"Article\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/end-to-end-guide-to-the-state-of-the-art-tool-for-fine-tuning/\", \"text\": \"Article\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/step-by-step-guide-to-supervised-fine-tune-llama-2-in-google-colab/\", \"text\": \"Article\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/introduction-to-weight-quantization/\", \"text\": \"Article\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/4-bit-llm-quantization-with-gptq/\", \"text\": \"Article\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/quantize-llama-models-with-gguf-and-llama-cpp/\", \"text\": \"Article\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/exllamav2-the-fastest-library-to-run-llms/\", \"text\": \"Article\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/merge-large-language-models-with-mergekit/\", \"text\": \"Article\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/create-mixtures-of-experts-with-mergekit/\", \"text\": \"Article\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/uncensor-any-llm-with-abliteration/\", \"text\": \"Article\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/improve-chatgpt-with-knowledge-graphs/\", \"text\": \"Article\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/decoding-strategies-in-large-language-models/\", \"text\": \"Article\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/blog/how-to-pick-between-data-science-and-other-data-roles/\", \"text\": \"Next\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com/book-a-call-ai/\", \"text\": \"Book Call Now\", \"title\": \"\", \"base_domain\": \"originshq.com\"}, {\"href\": \"https://originshq.com\", \"text\": \"Origins AI\", \"title\": \"\", \"base_domain\": \"originshq.com\"}], \"external\": [{\"href\": \"https://colab.research.google.com/drive/1Igs3WZuXAIv9X0vwqiE90QlEPys8e8Oa?usp=sharing\", \"text\": \"Notebook\", \"title\": \"\", \"base_domain\": \"google.com\"}, {\"href\": \"https://colab.research.google.com/drive/1obulZ1ROXHjYLn6PPZJwRR6GzgQogxxb?usp=sharing\", \"text\": \"Notebook\", \"title\": \"\", \"base_domain\": \"google.com\"}, {\"href\": \"https://colab.research.google.com/drive/1TsDKNo2riwVmU55gjuBgB1AXVtRRfRHW?usp=sharing\", \"text\": \"Notebook\", \"title\": \"\", \"base_domain\": \"google.com\"}, {\"href\": \"https://colab.research.google.com/drive/1b6nqC7UZVt8bx4MksX7s656GXPM-eWw4?usp=sharing\", \"text\": \"Notebook\", \"title\": \"\", \"base_domain\": \"google.com\"}, {\"href\": \"https://colab.research.google.com/drive/1s2eQlolcI1VGgDhqWIANfkfKvcKrMyNr?usp=sharing\", \"text\": \"Notebook\", \"title\": \"\", \"base_domain\": \"google.com\"}, {\"href\": \"https://colab.research.google.com/drive/1LcVUW5wsJTO2NGmozjji5CkC--646LgC\", \"text\": \"Notebook\", \"title\": \"\", \"base_domain\": \"google.com\"}, {\"href\": \"https://colab.research.google.com/drive/164cg_O7SV7G8kZr_JXqLd6VC7pd86-1Z?usp=sharing\", \"text\": \"Notebook\", \"title\": \"\", \"base_domain\": \"google.com\"}, {\"href\": \"https://colab.research.google.com/drive/1eHNWg9gnaXErdAa8_mcvjMupbSS6rDvi\", \"text\": \"Notebook\", \"title\": \"\", \"base_domain\": \"google.com\"}, {\"href\": \"https://colab.research.google.com/drive/15iFBr1xWgztXvhrj5I9fBv20c7CFOPBE?usp=sharing\", \"text\": \"Notebook\", \"title\": \"\", \"base_domain\": \"google.com\"}, {\"href\": \"https://colab.research.google.com/drive/1o_w0KastmEJNVwT5GoqMCciH-18ca5WS?usp=sharing\", \"text\": \"Notebook\", \"title\": \"\", \"base_domain\": \"google.com\"}, {\"href\": \"https://colab.research.google.com/drive/1Xu0BrCB7IShwSWKVcfAfhehwjDrDMH5m?usp=sharing\", \"text\": \"Notebook\", \"title\": \"\", \"base_domain\": \"google.com\"}, {\"href\": \"https://colab.research.google.com/drive/1PEQyJO1-f6j0S_XJ8DV50NkpzasXkrzd?usp=sharing\", \"text\": \"Notebook\", \"title\": \"\", \"base_domain\": \"google.com\"}, {\"href\": \"https://colab.research.google.com/drive/1DPr4mUQ92Cc-xf4GgAaB6dFcFnWIvqYi?usp=sharing\", \"text\": \"Notebook\", \"title\": \"\", \"base_domain\": \"google.com\"}, {\"href\": \"https://colab.research.google.com/drive/1lSvVDaRgqQp_mWK_jC9gydz6_-y6Aq4A?usp=sharing\", \"text\": \"Notebook\", \"title\": \"\", \"base_domain\": \"google.com\"}, {\"href\": \"https://colab.research.google.com/drive/1pL8k7m04mgE5jo2NrjGi8atB0j_37aDD?usp=sharing\", \"text\": \"Notebook\", \"title\": \"\", \"base_domain\": \"google.com\"}, {\"href\": \"https://colab.research.google.com/drive/1yrq4XBlxiA0fALtMoT2dwiACVc77PHou?usp=sharing\", \"text\": \"Notebook\", \"title\": \"\", \"base_domain\": \"google.com\"}, {\"href\": \"https://colab.research.google.com/drive/1_JS7JKJAQozD48-LhYdegcuuZ2ddgXfr?usp=sharing\", \"text\": \"Notebook\", \"title\": \"\", \"base_domain\": \"google.com\"}, {\"href\": \"https://colab.research.google.com/drive/1VYm3hOcvCpbGiqKZb141gJwjdmmCcVpR?usp=sharing\", \"text\": \"Notebook\", \"title\": \"\", \"base_domain\": \"google.com\"}, {\"href\": \"https://colab.research.google.com/drive/1mwhOSw9Y9bgEaIFKT4CLi0n18pXRM4cj?usp=sharing\", \"text\": \"Notebook\", \"title\": \"\", \"base_domain\": \"google.com\"}, {\"href\": \"https://colab.research.google.com/drive/19CJlOS5lI29g-B3dziNn93Enez1yiHk2?usp=sharing\", \"text\": \"Notebook\", \"title\": \"\", \"base_domain\": \"google.com\"}, {\"href\": \"https://www.youtube.com/watch?v=fNk_zzaMoSs&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab\", \"text\": \"3Blue1Brown \\u2013 The Essence of Linear Algebra\", \"title\": \"\", \"base_domain\": \"youtube.com\"}, {\"href\": \"https://www.youtube.com/watch?v=qBigTkBLU6g&list=PLblh5JKOoLUK0FLuzwntyYI10UQFUhsY9\", \"text\": \"StatQuest with Josh Starmer \\u2013 Statistics Fundamentals\", \"title\": \"\", \"base_domain\": \"youtube.com\"}, {\"href\": \"https://automata88.medium.com/list/cacc224d5e7d\", \"text\": \"AP Statistics Intuition by Ms Aerin\", \"title\": \"\", \"base_domain\": \"medium.com\"}, {\"href\": \"https://immersivemath.com/ila/learnmore.html\", \"text\": \"Immersive Linear Algebra\", \"title\": \"\", \"base_domain\": \"immersivemath.com\"}, {\"href\": \"https://www.khanacademy.org/math/linear-algebra\", \"text\": \"Khan Academy \\u2013 Linear Algebra\", \"title\": \"\", \"base_domain\": \"khanacademy.org\"}, {\"href\": \"https://www.khanacademy.org/math/calculus-1\", \"text\": \"Khan Academy \\u2013 Calculus\", \"title\": \"\", \"base_domain\": \"khanacademy.org\"}, {\"href\": \"https://www.khanacademy.org/math/statistics-probability\", \"text\": \"Khan Academy \\u2013 Probability and Statistics\", \"title\": \"\", \"base_domain\": \"khanacademy.org\"}, {\"href\": \"https://realpython.com/\", \"text\": \"Real Python\", \"title\": \"\", \"base_domain\": \"realpython.com\"}, {\"href\": \"https://www.youtube.com/watch?v=rfscVS0vtbw\", \"text\": \"freeCodeCamp \\u2013 Learn Python\", \"title\": \"\", \"base_domain\": \"youtube.com\"}, {\"href\": \"https://jakevdp.github.io/PythonDataScienceHandbook/\", \"text\": \"Python Data Science Handbook\", \"title\": \"\", \"base_domain\": \"github.io\"}, {\"href\": \"https://youtu.be/i_LwzRVP7bg\", \"text\": \"freeCodeCamp \\u2013 Machine Learning for Everybody\", \"title\": \"\", \"base_domain\": \"youtu.be\"}, {\"href\": \"https://www.udacity.com/course/intro-to-machine-learning--ud120\", \"text\": \"Udacity \\u2013 Intro to Machine Learning\", \"title\": \"\", \"base_domain\": \"udacity.com\"}, {\"href\": \"https://www.youtube.com/watch?v=aircAruvnKk\", \"text\": \"3Blue1Brown \\u2013 But what is a Neural Network?\", \"title\": \"\", \"base_domain\": \"youtube.com\"}, {\"href\": \"https://www.youtube.com/watch?v=VyWAvY2CF9c\", \"text\": \"freeCodeCamp \\u2013 Deep Learning Crash Course\", \"title\": \"\", \"base_domain\": \"youtube.com\"}, {\"href\": \"https://course.fast.ai/\", \"text\": \"Fast.ai \\u2013 Practical Deep Learning\", \"title\": \"\", \"base_domain\": \"fast.ai\"}, {\"href\": \"https://www.youtube.com/playlist?list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4\", \"text\": \"Patrick Loeber \\u2013 PyTorch Tutorials\", \"title\": \"\", \"base_domain\": \"youtube.com\"}, {\"href\": \"https://lena-voita.github.io/nlp_course/word_embeddings.html\", \"text\": \"Lena Voita \\u2013 Word Embeddings\", \"title\": \"\", \"base_domain\": \"github.io\"}, {\"href\": \"https://realpython.com/natural-language-processing-spacy-python/\", \"text\": \"RealPython \\u2013 NLP with spaCy in Python\", \"title\": \"\", \"base_domain\": \"realpython.com\"}, {\"href\": \"https://www.kaggle.com/learn-guide/natural-language-processing\", \"text\": \"Kaggle \\u2013 NLP Guide\", \"title\": \"\", \"base_domain\": \"kaggle.com\"}, {\"href\": \"https://jalammar.github.io/illustrated-word2vec/\", \"text\": \"Jay Alammar \\u2013 The Illustration Word2Vec\", \"title\": \"\", \"base_domain\": \"github.io\"}, {\"href\": \"https://jaketae.github.io/study/pytorch-rnn/\", \"text\": \"Jake Tae \\u2013 PyTorch RNN from Scratch\", \"title\": \"\", \"base_domain\": \"github.io\"}, {\"href\": \"https://colah.github.io/posts/2015-08-Understanding-LSTMs/\", \"text\": \"colah\\u2019s blog \\u2013 Understanding LSTM Networks\", \"title\": \"\", \"base_domain\": \"github.io\"}, {\"href\": \"https://www.youtube.com/watch?v=wjZofJX0v4M\", \"text\": \"Visual intro to Transformers\", \"title\": \"\", \"base_domain\": \"youtube.com\"}, {\"href\": \"https://bbycroft.net/llm\", \"text\": \"LLM Visualization\", \"title\": \"\", \"base_domain\": \"bbycroft.net\"}, {\"href\": \"https://www.youtube.com/watch?v=kCc8FmEb1nY\", \"text\": \"nanoGPT\", \"title\": \"\", \"base_domain\": \"youtube.com\"}, {\"href\": \"https://www.youtube.com/watch?v=zduSFxRajkE\", \"text\": \"here\", \"title\": \"\", \"base_domain\": \"youtube.com\"}, {\"href\": \"https://lilianweng.github.io/posts/2018-06-24-attention/\", \"text\": \"Attention? Attention!\", \"title\": \"\", \"base_domain\": \"github.io\"}, {\"href\": \"https://mlabonne.github.io/blog/posts/2023-06-07-Decoding_strategies.html\", \"text\": \"Decoding Strategies in LLMs\", \"title\": \"\", \"base_domain\": \"github.io\"}, {\"href\": \"https://arxiv.org/abs/2307.09288\", \"text\": \"Llama 3.1\", \"title\": \"\", \"base_domain\": \"arxiv.org\"}, {\"href\": \"https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1\", \"text\": \"FineWeb\", \"title\": \"\", \"base_domain\": \"huggingface.co\"}, {\"href\": \"https://www.together.ai/blog/redpajama-data-v2\", \"text\": \"RedPajama v2\", \"title\": \"\", \"base_domain\": \"together.ai\"}, {\"href\": \"https://github.com/huggingface/nanotron\", \"text\": \"nanotron\", \"title\": \"\", \"base_domain\": \"github.com\"}, {\"href\": \"https://github.com/huggingface/smollm\", \"text\": \"SmolLM2\", \"title\": \"\", \"base_domain\": \"github.com\"}, {\"href\": \"https://www.andrew.cmu.edu/course/11-667/lectures/W10L2%20Scaling%20Up%20Parallel%20Training.pdf\", \"text\": \"Parallel Training\", \"title\": \"\", \"base_domain\": \"cmu.edu\"}, {\"href\": \"https://arxiv.org/abs/2407.20018\", \"text\": \"Distributed Training\", \"title\": \"\", \"base_domain\": \"arxiv.org\"}, {\"href\": \"https://allenai.org/olmo\", \"text\": \"OLMo 2\", \"title\": \"\", \"base_domain\": \"allenai.org\"}, {\"href\": \"https://www.llm360.ai/\", \"text\": \"LLM360\", \"title\": \"\", \"base_domain\": \"llm360.ai\"}, {\"href\": \"https://github.com/mlabonne/llm-datasets\", \"text\": \"\\ud83d\\udcbe LLM Datasets\", \"title\": \"\", \"base_domain\": \"github.com\"}, {\"href\": \"https://arxiv.org/abs/2406.00770\", \"text\": \"Auto-Evol\", \"title\": \"\", \"base_domain\": \"arxiv.org\"}, {\"href\": \"https://huggingface.co/spaces/argilla/synthetic-data-generator\", \"text\": \"Synthetic Data Generator\", \"title\": \"\", \"base_domain\": \"huggingface.co\"}, {\"href\": \"https://github.com/NVIDIA/NeMo-Curator\", \"text\": \"NeMo-Curator\", \"title\": \"\", \"base_domain\": \"github.com\"}, {\"href\": \"https://distilabel.argilla.io/dev/sections/pipeline_samples/\", \"text\": \"Distilabel\", \"title\": \"\", \"base_domain\": \"argilla.io\"}, {\"href\": \"https://github.com/MinishLab/semhash\", \"text\": \"Semhash\", \"title\": \"\", \"base_domain\": \"github.com\"}, {\"href\": \"https://huggingface.co/docs/transformers/main/en/chat_templating\", \"text\": \"Chat Template\", \"title\": \"\", \"base_domain\": \"huggingface.co\"}, {\"href\": \"https://huggingface.co/blog/mlabonne/sft-llama3\", \"text\": \"Fine-tune Llama 3.1 Ultra-Efficiently with Unsloth\", \"title\": \"\", \"base_domain\": \"huggingface.co\"}, {\"href\": \"https://axolotl-ai-cloud.github.io/axolotl/\", \"text\": \"Axolotl \\u2013 Documentation\", \"title\": \"\", \"base_domain\": \"github.io\"}, {\"href\": \"https://parlance-labs.com/education/\", \"text\": \"Mastering LLMs\", \"title\": \"\", \"base_domain\": \"parlance-labs.com\"}, {\"href\": \"https://lightning.ai/pages/community/lora-insights/\", \"text\": \"LoRA insights\", \"title\": \"\", \"base_domain\": \"lightning.ai\"}, {\"href\": \"https://arxiv.org/abs/2305.18290\", \"text\": \"Direct Preference Optimization\", \"title\": \"\", \"base_domain\": \"arxiv.org\"}, {\"href\": \"https://arxiv.org/abs/1707.06347\", \"text\": \"Proximal Policy Optimization\", \"title\": \"\", \"base_domain\": \"arxiv.org\"}, {\"href\": \"https://huggingface.co/blog/rlhf\", \"text\": \"Illustrating RLHF\", \"title\": \"\", \"base_domain\": \"huggingface.co\"}, {\"href\": \"https://magazine.sebastianraschka.com/p/llm-training-rlhf-and-its-alternatives\", \"text\": \"LLM Training: RLHF and Its Alternatives\", \"title\": \"\", \"base_domain\": \"sebastianraschka.com\"}, {\"href\": \"https://huggingface.co/blog/pref-tuning\", \"text\": \"Preference Tuning LLMs\", \"title\": \"\", \"base_domain\": \"huggingface.co\"}, {\"href\": \"https://mlabonne.github.io/blog/posts/Fine_tune_Mistral_7b_with_DPO.html\", \"text\": \"Fine-tune Mistral-7b with DPO\", \"title\": \"\", \"base_domain\": \"github.io\"}, {\"href\": \"https://wandb.ai/alexander-vishnevskiy/dpo/reports/TRL-Original-DPO--Vmlldzo1NjI4MTc4\", \"text\": \"DPO Wandb logs\", \"title\": \"\", \"base_domain\": \"wandb.ai\"}, {\"href\": \"https://github.com/huggingface/evaluation-guidebook\", \"text\": \"Evaluation Guidebook\", \"title\": \"\", \"base_domain\": \"github.com\"}, {\"href\": \"https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard\", \"text\": \"Open LLM Leaderboard\", \"title\": \"\", \"base_domain\": \"huggingface.co\"}, {\"href\": \"https://github.com/EleutherAI/lm-evaluation-harness\", \"text\": \"Language Model Evaluation Harness\", \"title\": \"\", \"base_domain\": \"github.com\"}, {\"href\": \"https://github.com/huggingface/lighteval\", \"text\": \"Lighteval\", \"title\": \"\", \"base_domain\": \"github.com\"}, {\"href\": \"https://lmarena.ai/\", \"text\": \"Chatbot Arena\", \"title\": \"\", \"base_domain\": \"lmarena.ai\"}, {\"href\": \"https://github.com/ggerganov/llama.cpp\", \"text\": \"llama.cpp\", \"title\": \"\", \"base_domain\": \"github.com\"}, {\"href\": \"https://arxiv.org/abs/2210.17323\", \"text\": \"GPTQ\", \"title\": \"\", \"base_domain\": \"arxiv.org\"}, {\"href\": \"https://github.com/turboderp/exllamav2\", \"text\": \"EXL2\", \"title\": \"\", \"base_domain\": \"github.com\"}, {\"href\": \"https://arxiv.org/abs/2306.00978\", \"text\": \"AWQ\", \"title\": \"\", \"base_domain\": \"arxiv.org\"}, {\"href\": \"https://mlabonne.github.io/blog/posts/Introduction_to_Weight_Quantization.html\", \"text\": \"Introduction to Quantization\", \"title\": \"\", \"base_domain\": \"github.io\"}, {\"href\": \"https://mlabonne.github.io/blog/posts/Quantize_Llama_2_models_using_ggml.html\", \"text\": \"Quantize Llama models with llama.cpp\", \"title\": \"\", \"base_domain\": \"github.io\"}, {\"href\": \"https://mlabonne.github.io/blog/posts/4_bit_Quantization_with_GPTQ.html\", \"text\": \"4-bit LLM Quantization with GPTQ\", \"title\": \"\", \"base_domain\": \"github.io\"}, {\"href\": \"https://medium.com/friendliai/understanding-activation-aware-weight-quantization-awq-boosting-inference-serving-efficiency-in-10bb0faf63a8\", \"text\": \"Understanding Activation-Aware Weight Quantization\", \"title\": \"\", \"base_domain\": \"medium.com\"}, {\"href\": \"https://github.com/mit-han-lab/smoothquant/blob/main/examples/smoothquant_llama_demo.ipynb\", \"text\": \"SmoothQuant on Llama 2 7B\", \"title\": \"\", \"base_domain\": \"github.com\"}, {\"href\": \"https://www.deepspeed.ai/tutorials/model-compression/\", \"text\": \"DeepSpeed Model Compression\", \"title\": \"\", \"base_domain\": \"deepspeed.ai\"}, {\"href\": \"https://github.com/cg123/mergekit\", \"text\": \"mergekit\", \"title\": \"\", \"base_domain\": \"github.com\"}, {\"href\": \"https://arxiv.org/abs/2311.03099\", \"text\": \"DARE\", \"title\": \"\", \"base_domain\": \"arxiv.org\"}, {\"href\": \"https://openai.com/research/clip\", \"text\": \"CLIP\", \"title\": \"\", \"base_domain\": \"openai.com\"}, {\"href\": \"https://stability.ai/stable-image\", \"text\": \"Stable Diffusion\", \"title\": \"\", \"base_domain\": \"stability.ai\"}, {\"href\": \"https://llava-vl.github.io/\", \"text\": \"LLaVA\", \"title\": \"\", \"base_domain\": \"github.io\"}, {\"href\": \"https://mlabonne.github.io/blog/posts/2024-01-08_Merge_LLMs_with_mergekit.html\", \"text\": \"Merge LLMs with mergekit\", \"title\": \"\", \"base_domain\": \"github.io\"}, {\"href\": \"https://github.com/merveenoyan/smol-vision\", \"text\": \"Smol Vision\", \"title\": \"\", \"base_domain\": \"github.com\"}, {\"href\": \"https://huyenchip.com/2023/10/10/multimodal.html\", \"text\": \"Large Multimodal Models\", \"title\": \"\", \"base_domain\": \"huyenchip.com\"}, {\"href\": \"https://huggingface.co/blog/mlabonne/abliteration\", \"text\": \"Uncensor any LLM with abliteration\", \"title\": \"\", \"base_domain\": \"huggingface.co\"}, {\"href\": \"https://adamkarvonen.github.io/machine_learning/2024/06/11/sae-intuitions.html\", \"text\": \"Intuitive Explanation of SAEs\", \"title\": \"\", \"base_domain\": \"github.io\"}, {\"href\": \"https://huggingface.co/spaces/HuggingFaceH4/blogpost-scaling-test-time-compute\", \"text\": \"Scaling test-time compute\", \"title\": \"\", \"base_domain\": \"huggingface.co\"}, {\"href\": \"https://platform.openai.com/\", \"text\": \"OpenAI\", \"title\": \"\", \"base_domain\": \"openai.com\"}, {\"href\": \"https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview\", \"text\": \"Google\", \"title\": \"\", \"base_domain\": \"google.com\"}, {\"href\": \"https://docs.anthropic.com/claude/reference/getting-started-with-the-api\", \"text\": \"Anthropic\", \"title\": \"\", \"base_domain\": \"anthropic.com\"}, {\"href\": \"https://docs.cohere.com/docs\", \"text\": \"Cohere\", \"title\": \"\", \"base_domain\": \"cohere.com\"}, {\"href\": \"https://openrouter.ai/\", \"text\": \"OpenRouter\", \"title\": \"\", \"base_domain\": \"openrouter.ai\"}, {\"href\": \"https://huggingface.co/inference-api\", \"text\": \"Hugging Face\", \"title\": \"\", \"base_domain\": \"huggingface.co\"}, {\"href\": \"https://www.together.ai/\", \"text\": \"Together AI\", \"title\": \"\", \"base_domain\": \"together.ai\"}, {\"href\": \"https://huggingface.co/models\", \"text\": \"Hugging Face Hub\", \"title\": \"\", \"base_domain\": \"huggingface.co\"}, {\"href\": \"https://chatgpt.com/\", \"text\": \"Hugging Face Spaces\", \"title\": \"\", \"base_domain\": \"chatgpt.com\"}, {\"href\": \"https://lmstudio.ai/\", \"text\": \"LM Studio\", \"title\": \"\", \"base_domain\": \"lmstudio.ai\"}, {\"href\": \"https://ollama.ai/\", \"text\": \"Ollama\", \"title\": \"\", \"base_domain\": \"ollama.ai\"}, {\"href\": \"https://lmql.ai/\", \"text\": \"LMQL\", \"title\": \"\", \"base_domain\": \"lmql.ai\"}, {\"href\": \"https://github.com/outlines-dev/outlines\", \"text\": \"Outlines\", \"title\": \"\", \"base_domain\": \"github.com\"}, {\"href\": \"https://github.com/guidance-ai/guidance\", \"text\": \"Guidance\", \"title\": \"\", \"base_domain\": \"github.com\"}, {\"href\": \"https://www.kdnuggets.com/run-an-llm-locally-with-lm-studio\", \"text\": \"Run an LLM locally with LM Studio\", \"title\": \"\", \"base_domain\": \"kdnuggets.com\"}, {\"href\": \"https://www.promptingguide.ai/\", \"text\": \"Prompt engineering guide\", \"title\": \"\", \"base_domain\": \"promptingguide.ai\"}, {\"href\": \"https://outlines-dev.github.io/outlines/quickstart/\", \"text\": \"Outlines \\u2013 Quickstart\", \"title\": \"\", \"base_domain\": \"github.io\"}, {\"href\": \"https://lmql.ai/docs/language/overview.html\", \"text\": \"LMQL \\u2013 Overview\", \"title\": \"\", \"base_domain\": \"lmql.ai\"}, {\"href\": \"https://www.trychroma.com/\", \"text\": \"Chroma\", \"title\": \"\", \"base_domain\": \"trychroma.com\"}, {\"href\": \"https://www.pinecone.io/\", \"text\": \"Pinecone\", \"title\": \"\", \"base_domain\": \"pinecone.io\"}, {\"href\": \"https://milvus.io/\", \"text\": \"Milvus\", \"title\": \"\", \"base_domain\": \"milvus.io\"}, {\"href\": \"https://faiss.ai/\", \"text\": \"FAISS\", \"title\": \"\", \"base_domain\": \"faiss.ai\"}, {\"href\": \"https://github.com/spotify/annoy\", \"text\": \"Annoy\", \"title\": \"\", \"base_domain\": \"github.com\"}, {\"href\": \"https://python.langchain.com/docs/modules/data_connection/document_transformers/\", \"text\": \"LangChain \\u2013 Text splitters\", \"title\": \"\", \"base_domain\": \"langchain.com\"}, {\"href\": \"https://www.sbert.net/\", \"text\": \"Sentence Transformers library\", \"title\": \"\", \"base_domain\": \"sbert.net\"}, {\"href\": \"https://huggingface.co/spaces/mteb/leaderboard\", \"text\": \"MTEB Leaderboard\", \"title\": \"\", \"base_domain\": \"huggingface.co\"}, {\"href\": \"https://www.datacamp.com/blog/the-top-5-vector-databases\", \"text\": \"The Top 5 Vector Databases\", \"title\": \"\", \"base_domain\": \"datacamp.com\"}, {\"href\": \"https://python.langchain.com/docs/get_started/introduction\", \"text\": \"LangChain\", \"title\": \"\", \"base_domain\": \"langchain.com\"}, {\"href\": \"https://docs.llamaindex.ai/en/stable/\", \"text\": \"LlamaIndex\", \"title\": \"\", \"base_domain\": \"llamaindex.ai\"}, {\"href\": \"https://github.com/IntelLabs/fastRAG\", \"text\": \"FastRAG\", \"title\": \"\", \"base_domain\": \"github.com\"}, {\"href\": \"https://arxiv.org/abs/2212.10496\", \"text\": \"HyDE\", \"title\": \"\", \"base_domain\": \"arxiv.org\"}, {\"href\": \"https://github.com/explodinggradients/ragas/tree/main\", \"text\": \"Ragas\", \"title\": \"\", \"base_domain\": \"github.com\"}, {\"href\": \"https://github.com/confident-ai/deepeval\", \"text\": \"DeepEval\", \"title\": \"\", \"base_domain\": \"github.com\"}, {\"href\": \"https://docs.llamaindex.ai/en/stable/getting_started/concepts.html\", \"text\": \"Llamaindex \\u2013 High-level concepts\", \"title\": \"\", \"base_domain\": \"llamaindex.ai\"}, {\"href\": \"https://www.pinecone.io/learn/series/langchain/langchain-retrieval-augmentation/\", \"text\": \"Pinecone \\u2013 Retrieval Augmentation\", \"title\": \"\", \"base_domain\": \"pinecone.io\"}, {\"href\": \"https://python.langchain.com/docs/use_cases/question_answering/quickstart\", \"text\": \"LangChain \\u2013 Q&A with RAG\", \"title\": \"\", \"base_domain\": \"langchain.com\"}, {\"href\": \"https://python.langchain.com/docs/modules/memory/types/\", \"text\": \"LangChain \\u2013 Memory types\", \"title\": \"\", \"base_domain\": \"langchain.com\"}, {\"href\": \"https://docs.ragas.io/en/stable/concepts/metrics/index.html\", \"text\": \"RAG pipeline \\u2013 Metrics\", \"title\": \"\", \"base_domain\": \"ragas.io\"}, {\"href\": \"https://github.com/Raudaschl/rag-fusion\", \"text\": \"RAG-fusion\", \"title\": \"\", \"base_domain\": \"github.com\"}, {\"href\": \"https://github.com/stanfordnlp/dspy\", \"text\": \"DSPy\", \"title\": \"\", \"base_domain\": \"github.com\"}, {\"href\": \"https://blog.langchain.dev/query-construction/\", \"text\": \"LangChain \\u2013 Query Construction\", \"title\": \"\", \"base_domain\": \"langchain.dev\"}, {\"href\": \"https://python.langchain.com/docs/use_cases/qa_structured/sql\", \"text\": \"LangChain \\u2013 SQL\", \"title\": \"\", \"base_domain\": \"langchain.com\"}, {\"href\": \"https://www.pinecone.io/learn/series/langchain/langchain-agents/\", \"text\": \"Pinecone \\u2013 LLM agents\", \"title\": \"\", \"base_domain\": \"pinecone.io\"}, {\"href\": \"https://lilianweng.github.io/posts/2023-06-23-agent/\", \"text\": \"LLM Powered Autonomous Agents\", \"title\": \"\", \"base_domain\": \"github.io\"}, {\"href\": \"https://blog.langchain.dev/applying-openai-rag/\", \"text\": \"LangChain \\u2013 OpenAI\\u2019s RAG\", \"title\": \"\", \"base_domain\": \"langchain.dev\"}, {\"href\": \"https://dspy-docs.vercel.app/docs/building-blocks/solving_your_task\", \"text\": \"DSPy in 8 Steps\", \"title\": \"\", \"base_domain\": \"vercel.app\"}, {\"href\": \"https://arxiv.org/abs/1911.02150\", \"text\": \"Multi-Query Attention\", \"title\": \"\", \"base_domain\": \"arxiv.org\"}, {\"href\": \"https://arxiv.org/abs/2305.13245\", \"text\": \"Grouped-Query Attention\", \"title\": \"\", \"base_domain\": \"arxiv.org\"}, {\"href\": \"https://huggingface.co/docs/transformers/main/en/perf_infer_gpu_one\", \"text\": \"GPU Inference\", \"title\": \"\", \"base_domain\": \"huggingface.co\"}, {\"href\": \"https://www.databricks.com/blog/llm-inference-performance-engineering-best-practices\", \"text\": \"LLM Inference\", \"title\": \"\", \"base_domain\": \"databricks.com\"}, {\"href\": \"https://huggingface.co/docs/transformers/main/en/llm_tutorial_optimization\", \"text\": \"Optimizing LLMs for Speed and Memory\", \"title\": \"\", \"base_domain\": \"huggingface.co\"}, {\"href\": \"https://huggingface.co/blog/assisted-generation\", \"text\": \"Assisted Generation\", \"title\": \"\", \"base_domain\": \"huggingface.co\"}, {\"href\": \"https://github.com/oobabooga/text-generation-webui\", \"text\": \"oobabooga\", \"title\": \"\", \"base_domain\": \"github.com\"}, {\"href\": \"https://github.com/LostRuins/koboldcpp\", \"text\": \"kobold.cpp\", \"title\": \"\", \"base_domain\": \"github.com\"}, {\"href\": \"https://www.gradio.app/\", \"text\": \"Gradio\", \"title\": \"\", \"base_domain\": \"gradio.app\"}, {\"href\": \"https://docs.streamlit.io/\", \"text\": \"Streamlit\", \"title\": \"\", \"base_domain\": \"streamlit.io\"}, {\"href\": \"https://huggingface.co/spaces\", \"text\": \"Hugging Face Spaces\", \"title\": \"\", \"base_domain\": \"huggingface.co\"}, {\"href\": \"https://github.com/huggingface/text-generation-inference\", \"text\": \"TGI\", \"title\": \"\", \"base_domain\": \"github.com\"}, {\"href\": \"https://github.com/vllm-project/vllm/tree/main\", \"text\": \"vLLM\", \"title\": \"\", \"base_domain\": \"github.com\"}, {\"href\": \"https://github.com/mlc-ai/mlc-llm\", \"text\": \"MLC LLM\", \"title\": \"\", \"base_domain\": \"github.com\"}, {\"href\": \"https://github.com/wangzhaode/mnn-llm/blob/master/README_en.md\", \"text\": \"mnn-llm\", \"title\": \"\", \"base_domain\": \"github.com\"}, {\"href\": \"https://docs.streamlit.io/knowledge-base/tutorials/build-conversational-apps\", \"text\": \"Streamlit \\u2013 Build a basic LLM app\", \"title\": \"\", \"base_domain\": \"streamlit.io\"}, {\"href\": \"https://huggingface.co/blog/sagemaker-huggingface-llm\", \"text\": \"HF LLM Inference Container\", \"title\": \"\", \"base_domain\": \"huggingface.co\"}, {\"href\": \"https://www.philschmid.de/\", \"text\": \"Philschmid blog\", \"title\": \"\", \"base_domain\": \"philschmid.de\"}, {\"href\": \"https://hamel.dev/notes/llm/inference/03_inference.html\", \"text\": \"Optimizing Latency\", \"title\": \"\", \"base_domain\": \"hamel.dev\"}, {\"href\": \"https://github.com/leondz/garak/\", \"text\": \"garak\", \"title\": \"\", \"base_domain\": \"github.com\"}, {\"href\": \"https://github.com/langfuse/langfuse\", \"text\": \"langfuse\", \"title\": \"\", \"base_domain\": \"github.com\"}, {\"href\": \"https://owasp.org/www-project-top-10-for-large-language-model-applications/\", \"text\": \"OWASP LLM Top 10\", \"title\": \"\", \"base_domain\": \"owasp.org\"}, {\"href\": \"https://github.com/jthack/PIPE\", \"text\": \"Prompt Injection Primer\", \"title\": \"\", \"base_domain\": \"github.com\"}, {\"href\": \"https://llmsecurity.net/\", \"text\": \"LLM Security\", \"title\": \"\", \"base_domain\": \"llmsecurity.net\"}, {\"href\": \"https://twitter.com/llm_sec\", \"text\": \"@llm_sec\", \"title\": \"\", \"base_domain\": \"twitter.com\"}, {\"href\": \"https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/red-teaming\", \"text\": \"Red teaming LLMs\", \"title\": \"\", \"base_domain\": \"microsoft.com\"}]}",
    "metadata": "{\"title\": \"Top AI/LLM learning resource in 2025 - Origins AI\", \"description\": null, \"keywords\": null, \"author\": \"apoorvakumar169\", \"og:locale\": \"en_US\", \"og:type\": \"article\", \"og:title\": \"Top AI/LLM learning resource in 2025 - Origins AI\", \"og:description\": \"The Blog is organized into three main segments: \\ud83d\\udcdd Notebooks Below is a collection of notebooks and articles dedicated to LLMs. Tools Notebook Name Description Notebook \\ud83e\\uddd0 LLM AutoEval Evaluate your LLMs automatically using RunPod. Notebook \\ud83e\\udd71 LazyMergekit Merge models effortlessly using MergeKit with a single click. Notebook \\ud83e\\udd8e LazyAxolotl Fine-tune models in the cloud [\\u2026]\", \"og:url\": \"https://originshq.com/blog/top-ai-llm-learning-resource-in-2025/\", \"og:site_name\": \"Origins AI\", \"og:image\": \"https://originshq.com/wp-content/uploads/2025/01/top_learning_resource_ai_llm_in_2025.jpg\", \"og:image:width\": \"1680\", \"og:image:height\": \"945\", \"og:image:type\": \"image/jpeg\", \"twitter:card\": \"summary_large_image\", \"twitter:creator\": \"@origins_hq\", \"twitter:site\": \"@origins_hq\", \"twitter:label1\": \"Written by\", \"twitter:data1\": \"apoorvakumar169\", \"twitter:label2\": \"Est. reading time\", \"twitter:data2\": \"17 minutes\"}",
    "screenshot": ""
  }
]